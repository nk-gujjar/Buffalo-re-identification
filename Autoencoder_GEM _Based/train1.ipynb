{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef46d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 17:21:29.032688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Input, Dense, UpSampling2D, Conv2D, Conv2DTranspose, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eccbb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Organization and Splitting\n",
    "def organize_data(data_dir, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Organize data from folders and split into train/test sets\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing subfolders with cattle images\n",
    "        test_size: Proportion of data for testing\n",
    "    \n",
    "    Returns:\n",
    "        train_data, test_data: Lists of (image_path, label) tuples\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # Iterate through each subfolder\n",
    "    for folder_name in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            # Get all images in the subfolder\n",
    "            for img_name in os.listdir(folder_path):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(folder_path, img_name)\n",
    "                    all_data.append((img_path, folder_name))\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    train_data, test_data = train_test_split(all_data, test_size=test_size, stratify=[x[1] for x in all_data], random_state=42)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "def create_data_directories(train_data, test_data, output_dir):\n",
    "    \"\"\"\n",
    "    Create train and test directories with class subdirectories\n",
    "    \n",
    "    Args:\n",
    "        train_data: List of (image_path, label) tuples for training\n",
    "        test_data: List of (image_path, label) tuples for testing\n",
    "        output_dir: Directory to create train and test folders\n",
    "    \"\"\"\n",
    "    # Create main directories\n",
    "    train_dir = os.path.join(output_dir, 'train')\n",
    "    test_dir = os.path.join(output_dir, 'test')\n",
    "    \n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # Create class subdirectories and copy images\n",
    "    import shutil\n",
    "    \n",
    "    # Process training data\n",
    "    for img_path, label in train_data:\n",
    "        label_dir = os.path.join(train_dir, label)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy the image\n",
    "        shutil.copy(img_path, os.path.join(label_dir, os.path.basename(img_path)))\n",
    "    \n",
    "    # Process testing data\n",
    "    for img_path, label in test_data:\n",
    "        label_dir = os.path.join(test_dir, label)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy the image\n",
    "        shutil.copy(img_path, os.path.join(label_dir, os.path.basename(img_path)))\n",
    "    \n",
    "    return train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bdb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create Data Generators\n",
    "def create_data_generators(train_dir, test_dir, img_size=(224, 224), batch_size=32):\n",
    "    \"\"\"\n",
    "    Create data generators for training and testing\n",
    "    \n",
    "    Args:\n",
    "        train_dir: Directory containing training data\n",
    "        test_dir: Directory containing testing data\n",
    "        img_size: Input image dimensions\n",
    "        batch_size: Batch size for training\n",
    "    \n",
    "    Returns:\n",
    "        train_generator, validation_generator: Data generators\n",
    "    \"\"\"\n",
    "    # Data augmentation for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.1  # Use 10% of training data for validation\n",
    "    )\n",
    "    \n",
    "    # Only rescaling for testing\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Training generator with validation split\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='input',  # For autoencoder, input is the target\n",
    "        subset='training'\n",
    "    )\n",
    "    \n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='input',\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    # Test generator\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='input',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b171ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build Autoencoder with EfficientNet Encoder\n",
    "def build_autoencoder(img_size=(224, 224, 3), latent_dim=128):\n",
    "    \"\"\"\n",
    "    Build autoencoder with EfficientNet encoder and custom decoder\n",
    "    \n",
    "    Args:\n",
    "        img_size: Input image dimensions\n",
    "        latent_dim: Dimension of the latent space\n",
    "    \n",
    "    Returns:\n",
    "        autoencoder: Complete autoencoder model\n",
    "        encoder: Encoder part of the model for feature extraction\n",
    "    \"\"\"\n",
    "    # Base EfficientNet model (encoder)\n",
    "    base_model = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=img_size,\n",
    "        pooling='avg'\n",
    "    )\n",
    "    \n",
    "    # Freeze the pre-trained weights\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = Input(shape=img_size)\n",
    "    \n",
    "    # Encoder\n",
    "    x = base_model(inputs)\n",
    "    x = Dense(latent_dim, activation='relu')(x)\n",
    "    \n",
    "    # Define encoder model for feature extraction\n",
    "    encoder = Model(inputs, x, name='encoder')\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(7 * 7 * 64, activation='relu')(x)\n",
    "    x = Reshape((7, 7, 64))(x)\n",
    "    \n",
    "    x = Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu')(x)  # 14x14\n",
    "    x = Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation='relu')(x)  # 28x28\n",
    "    x = Conv2DTranspose(16, (3, 3), strides=2, padding='same', activation='relu')(x)  # 56x56\n",
    "    x = Conv2DTranspose(8, (3, 3), strides=2, padding='same', activation='relu')(x)   # 112x112\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Conv2DTranspose(3, (3, 3), strides=2, padding='same', activation='sigmoid')(x)  # 224x224\n",
    "    \n",
    "    # Define autoencoder model\n",
    "    autoencoder = Model(inputs, outputs, name='autoencoder')\n",
    "    \n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aae791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Implement GEM (Gradient Episodic Memory) - FIXED\n",
    "class GradientEpisodicMemory:\n",
    "    def __init__(self, memory_size=200):\n",
    "        \"\"\"\n",
    "        Initialize GEM\n",
    "        \n",
    "        Args:\n",
    "            memory_size: Maximum number of samples to store in memory\n",
    "        \"\"\"\n",
    "        self.memory_size = memory_size\n",
    "        self.memory_x = []\n",
    "        self.memory_y = []\n",
    "        self.memory_task_ids = []  # This was missing in the previous implementation\n",
    "        self.task_memory_sizes = defaultdict(int)\n",
    "    \n",
    "    def add_example(self, x, y, task_id):\n",
    "        \"\"\"\n",
    "        Add an example to episodic memory\n",
    "        \n",
    "        Args:\n",
    "            x: Input data\n",
    "            y: Target output\n",
    "            task_id: Identifier for the task\n",
    "        \"\"\"\n",
    "        # If memory is full, replace a random sample from the same task\n",
    "        if len(self.memory_x) >= self.memory_size:\n",
    "            task_indices = [i for i, task in enumerate(self.memory_task_ids) if task == task_id]\n",
    "            if task_indices:\n",
    "                replace_idx = random.choice(task_indices)\n",
    "                self.memory_x[replace_idx] = x\n",
    "                self.memory_y[replace_idx] = y\n",
    "            else:\n",
    "                # If no samples from this task, replace a random sample\n",
    "                replace_idx = random.randrange(len(self.memory_x))\n",
    "                self.memory_x[replace_idx] = x\n",
    "                self.memory_y[replace_idx] = y\n",
    "                self.memory_task_ids[replace_idx] = task_id\n",
    "        else:\n",
    "            # If memory is not full, just add the example\n",
    "            self.memory_x.append(x)\n",
    "            self.memory_y.append(y)\n",
    "            self.memory_task_ids.append(task_id)\n",
    "            self.task_memory_sizes[task_id] += 1\n",
    "    \n",
    "    def get_memory_batch(self, batch_size=32):\n",
    "        \"\"\"\n",
    "        Get a batch of samples from memory\n",
    "        \n",
    "        Args:\n",
    "            batch_size: Size of the batch to return\n",
    "        \n",
    "        Returns:\n",
    "            memory_batch_x, memory_batch_y: Batch of samples from memory\n",
    "        \"\"\"\n",
    "        if not self.memory_x:\n",
    "            return None, None\n",
    "        \n",
    "        # Sample indices randomly\n",
    "        indices = random.sample(range(len(self.memory_x)), min(batch_size, len(self.memory_x)))\n",
    "        \n",
    "        # Get the batch\n",
    "        memory_batch_x = [self.memory_x[i] for i in indices]\n",
    "        memory_batch_y = [self.memory_y[i] for i in indices]\n",
    "        \n",
    "        return np.array(memory_batch_x), np.array(memory_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450911f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Training function with GEM\n",
    "def train_with_gem(autoencoder, train_generator, validation_generator, gem, epochs=30, batch_size=32):\n",
    "    \"\"\"\n",
    "    Train the autoencoder with GEM\n",
    "    \n",
    "    Args:\n",
    "        autoencoder: Autoencoder model\n",
    "        train_generator: Training data generator\n",
    "        validation_generator: Validation data generator\n",
    "        gem: GradientEpisodicMemory instance\n",
    "        epochs: Number of epochs to train\n",
    "        batch_size: Batch size\n",
    "    \n",
    "    Returns:\n",
    "        history: Training history\n",
    "    \"\"\"\n",
    "    # Compile the model\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint('autoencoder_best.h5', save_best_only=True, monitor='val_loss'),\n",
    "        EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6)\n",
    "    ]\n",
    "    \n",
    "    # Lists to store losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        epoch_train_losses = []\n",
    "        \n",
    "        # Iterate through batches\n",
    "        for batch_idx in range(len(train_generator)):\n",
    "            # Get batch of data\n",
    "            x_batch, _ = train_generator.next()\n",
    "            \n",
    "            # Train on the batch\n",
    "            loss = autoencoder.train_on_batch(x_batch, x_batch)\n",
    "            epoch_train_losses.append(loss)\n",
    "            \n",
    "            # Add examples to memory\n",
    "            for i in range(len(x_batch)):\n",
    "                gem.add_example(x_batch[i], x_batch[i], 0)  # Task ID is 0 for simplicity\n",
    "            \n",
    "            # If memory has samples, train on a batch from memory\n",
    "            memory_x, memory_y = gem.get_memory_batch(batch_size)\n",
    "            if memory_x is not None:\n",
    "                autoencoder.train_on_batch(memory_x, memory_y)\n",
    "            \n",
    "            print(f\"\\rBatch {batch_idx+1}/{len(train_generator)} - Loss: {loss:.4f}\", end=\"\")\n",
    "        \n",
    "        # Compute validation loss\n",
    "        val_loss = 0\n",
    "        val_steps = 0\n",
    "        for _ in range(len(validation_generator)):\n",
    "            x_val, _ = validation_generator.next()\n",
    "            val_batch_loss = autoencoder.evaluate(x_val, x_val, verbose=0)\n",
    "            val_loss += val_batch_loss\n",
    "            val_steps += 1\n",
    "        \n",
    "        val_loss /= val_steps\n",
    "        \n",
    "        # Store losses\n",
    "        train_loss = np.mean(epoch_train_losses)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': train_losses,\n",
    "        'val_loss': val_losses\n",
    "    }\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815ba622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Feature extraction function\n",
    "def extract_features(encoder, data_generator):\n",
    "    \"\"\"\n",
    "    Extract features using the encoder\n",
    "    \n",
    "    Args:\n",
    "        encoder: Encoder model\n",
    "        data_generator: Data generator\n",
    "    \n",
    "    Returns:\n",
    "        features: Extracted features\n",
    "        labels: Corresponding labels\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate through all batches\n",
    "    for i in range(len(data_generator)):\n",
    "        # Get batch of data\n",
    "        x_batch, _ = data_generator.next()\n",
    "        \n",
    "        # Extract features\n",
    "        batch_features = encoder.predict(x_batch)\n",
    "        \n",
    "        # Store features and labels\n",
    "        features.append(batch_features)\n",
    "        \n",
    "        # For labels, we'll use the directory names\n",
    "        batch_labels = data_generator.classes[i*data_generator.batch_size:(i+1)*data_generator.batch_size]\n",
    "        labels.extend(batch_labels)\n",
    "    \n",
    "    features = np.vstack(features)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22b904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Visualization function\n",
    "def visualize_results(history, features, labels):\n",
    "    \"\"\"\n",
    "    Visualize training results and extracted features\n",
    "    \n",
    "    Args:\n",
    "        history: Training history\n",
    "        features: Extracted features\n",
    "        labels: Corresponding labels\n",
    "    \"\"\"\n",
    "    # Create a figure with subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot training and validation loss\n",
    "    axs[0].plot(history['train_loss'], label='Training Loss')\n",
    "    axs[0].plot(history['val_loss'], label='Validation Loss')\n",
    "    axs[0].set_title('Training and Validation Loss')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "    \n",
    "    # Plot feature distribution using PCA\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    features_2d = pca.fit_transform(features)\n",
    "    \n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.jet(np.linspace(0, 1, len(unique_labels)))\n",
    "    \n",
    "    for i, label in enumerate(unique_labels):\n",
    "        mask = labels == label\n",
    "        axs[1].scatter(features_2d[mask, 0], features_2d[mask, 1], c=[colors[i]], label=f'Class {label}')\n",
    "    \n",
    "    axs[1].set_title('Feature Distribution (PCA)')\n",
    "    axs[1].set_xlabel('Principal Component 1')\n",
    "    axs[1].set_ylabel('Principal Component 2')\n",
    "    axs[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_results.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfddaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Replace with your actual data directory\n",
    "data_dir = \"../../dataset/All-images\" \n",
    "output_dir = \"./cattle_classification_output_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0af086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing data...\n",
      "Creating data directories...\n",
      "Creating data generators...\n",
      "Found 14309 images belonging to 1340 classes.\n",
      "Found 840 images belonging to 1340 classes.\n",
      "Found 3788 images belonging to 1340 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "# Organize data\n",
    "print(\"Organizing data...\")\n",
    "train_data, test_data = organize_data(data_dir)\n",
    "    \n",
    "# Create data directories\n",
    "print(\"Creating data directories...\")\n",
    "train_dir, test_dir = create_data_directories(train_data, test_data, output_dir)\n",
    "    \n",
    "# Create data generators\n",
    "print(\"Creating data generators...\")\n",
    "train_generator, validation_generator, test_generator = create_data_generators(train_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "733dd1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Main execution function\n",
    "def main(data_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing cattle image subfolders\n",
    "        output_dir: Directory to store processed data and results\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Build autoencoder\n",
    "    print(\"Building autoencoder...\")\n",
    "    autoencoder, encoder = build_autoencoder()\n",
    "    \n",
    "    # Initialize GEM\n",
    "    print(\"Initializing Gradient Episodic Memory...\")\n",
    "    gem = GradientEpisodicMemory()\n",
    "    \n",
    "    # Train with GEM\n",
    "    print(\"Training with GEM...\")\n",
    "    history = train_with_gem(autoencoder, train_generator, validation_generator, gem)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac8a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building autoencoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 17:26:16.514352: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Gradient Episodic Memory...\n",
      "Training with GEM...\n",
      "Epoch 1/30\n",
      "Batch 448/448 - Loss: 0.0468\n",
      "Epoch 1/30 - Train Loss: 0.0374 - Val Loss: 0.1087\n",
      "Epoch 2/30\n",
      "Batch 448/448 - Loss: 0.0470\n",
      "Epoch 2/30 - Train Loss: 0.0257 - Val Loss: 0.0341\n",
      "Epoch 3/30\n",
      "Batch 448/448 - Loss: 0.0247\n",
      "Epoch 3/30 - Train Loss: 0.0223 - Val Loss: 0.0206\n",
      "Epoch 4/30\n",
      "Batch 448/448 - Loss: 0.0134\n",
      "Epoch 4/30 - Train Loss: 0.0201 - Val Loss: 0.1065\n",
      "Epoch 5/30\n",
      "Batch 448/448 - Loss: 0.0192\n",
      "Epoch 5/30 - Train Loss: 0.0184 - Val Loss: 0.1413\n",
      "Epoch 6/30\n",
      "Batch 448/448 - Loss: 0.0157\n",
      "Epoch 6/30 - Train Loss: 0.0170 - Val Loss: 0.0439\n",
      "Epoch 7/30\n",
      "Batch 448/448 - Loss: 0.0150\n",
      "Epoch 7/30 - Train Loss: 0.0159 - Val Loss: 0.0734\n",
      "Epoch 8/30\n",
      "Batch 448/448 - Loss: 0.0234\n",
      "Epoch 8/30 - Train Loss: 0.0149 - Val Loss: 0.0179\n",
      "Epoch 9/30\n",
      "Batch 448/448 - Loss: 0.0081\n",
      "Epoch 9/30 - Train Loss: 0.0141 - Val Loss: 0.0546\n",
      "Epoch 10/30\n",
      "Batch 448/448 - Loss: 0.0122\n",
      "Epoch 10/30 - Train Loss: 0.0133 - Val Loss: 0.0370\n",
      "Epoch 11/30\n",
      "Batch 128/448 - Loss: 0.0116"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    main(data_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f06e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Extract features\n",
    "print(\"Extracting features...\")\n",
    "test_features, test_labels = extract_features(encoder, test_generator)\n",
    "    \n",
    "    # Visualize results\n",
    "print(\"Visualizing results...\")\n",
    "visualize_results(history, test_features, test_labels)\n",
    "    \n",
    "    # Save models\n",
    "print(\"Saving models...\")\n",
    "autoencoder.save(os.path.join(output_dir, 'autoencoder_model.h5'))\n",
    "encoder.save(os.path.join(output_dir, 'encoder_model.h5'))\n",
    "    \n",
    "print(\"Process completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89918357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
