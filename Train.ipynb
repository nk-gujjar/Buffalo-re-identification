{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "# !pip install tensorflow-gpu\n",
    "# !pip install torch\n",
    "# !pip torchvision\n",
    "# !pip transformers\n",
    "# !pip install timm\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install ipykernel\n",
    "\n",
    "# !pip install jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter notebook\n",
    "# !pip install --upgrade numpy\n",
    "# !pip uninstall tensorflow -y\n",
    "# !pip install tensorflow transformers torch torchvision timm pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaBRBTmjHNyH",
    "outputId": "20e7021a-59c9-453b-bdf5-fa94397e1131"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 18:15:02.377634: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import transformers\n",
    "# import timm\n",
    "\n",
    "# print(\"Torch version:\", torch.__version__)\n",
    "# print(\"NumPy version:\", np.__version__)\n",
    "# print(\"TensorFlow version:\", tf.__version__)\n",
    "# print(\"Transformers version:\", transformers.__version__)\n",
    "# print(\"Timm version:\", timm.__version__)\n",
    "\n",
    "\n",
    "# Install required libraries\n",
    "# !pip install torch torchvision transformers timm pandas scikit-learn\n",
    "\n",
    "# Import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from transformers import ViTModel, ViTConfig\n",
    "import timm\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d0pofeBTRAFO"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# data_dir = '/content/drive/MyDrive/data'\n",
    "\n",
    "# def check_empty_dirs(root_dir):\n",
    "#     empty = []\n",
    "#     for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "#         if not filenames and \"val\" in dirpath:  # Check only train/val/test\n",
    "#             empty.append(dirpath)\n",
    "#     return empty\n",
    "\n",
    "# empty_dirs = check_empty_dirs(data_dir)\n",
    "# if empty_dirs:\n",
    "#     print(\"ðŸš¨ Empty directories found:\", empty_dirs)\n",
    "# else:\n",
    "#     print(\"âœ… No empty directories found.\")\n",
    "\n",
    "# import os\n",
    "# os.environ[\"HF_HOME\"] = \"/workspace/awadh/nvidia/Nitesh/huggingface_cache\"\n",
    "# os.environ[\"HUGGINGFACE_HUB_CACHE\"] = \"/workspace/awadh/nvidia/Nitesh/huggingface_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "i5VuUl8vN98i"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Custom ImageFolder to skip empty directories\n",
    "class SafeImageFolder(datasets.ImageFolder):\n",
    "    @staticmethod\n",
    "    def make_dataset(\n",
    "        directory, class_to_idx, extensions=None, is_valid_file=None, allow_empty=False\n",
    "    ):\n",
    "        instances = []\n",
    "        directory = os.path.expanduser(directory)\n",
    "\n",
    "        for target_class in sorted(class_to_idx.keys()):\n",
    "            target_dir = os.path.join(directory, target_class)\n",
    "            if not os.path.isdir(target_dir):\n",
    "                continue\n",
    "\n",
    "            # Check if directory has valid files\n",
    "            has_files = any(\n",
    "                datasets.folder.has_file_allowed_extension(os.path.join(root, fname), extensions)\n",
    "                for root, _, fnames in os.walk(target_dir, followlinks=True)\n",
    "                for fname in fnames\n",
    "            )\n",
    "\n",
    "            if not has_files and not allow_empty:\n",
    "                continue  # Skip empty directory if allow_empty is False\n",
    "\n",
    "            # Collect valid files\n",
    "            for root, _, fnames in os.walk(target_dir, followlinks=True):\n",
    "                for fname in sorted(fnames):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    if (is_valid_file or datasets.folder.has_file_allowed_extension(path, extensions)):\n",
    "                        item = (path, class_to_idx[target_class])\n",
    "                        instances.append(item)\n",
    "        return instances\n",
    "\n",
    "# ImageNet Mean and Std\n",
    "IMAGENET_DEFAULT_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_DEFAULT_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Define transformations\n",
    "img_size = 224\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)  # âœ… Corrected\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)  # âœ… Corrected\n",
    "])\n",
    "\n",
    "# Load datasets with SafeImageFolder\n",
    "data_dir = '../dataset/all-data'\n",
    "train_dataset = SafeImageFolder(root=f'{data_dir}/train', transform=train_transform)\n",
    "val_dataset = SafeImageFolder(root=f'{data_dir}/val', transform=val_transform)\n",
    "test_dataset = SafeImageFolder(root=f'{data_dir}/test', transform=val_transform)\n",
    "\n",
    "# Create data loaders (fixed batch_size typo)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)  # âœ… Fixed b_size -> batch_size\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)  # âœ… Fixed b_size -> batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "referenced_widgets": [
      "d391cf167fc5475aaa77282703c6623c"
     ]
    },
    "id": "I-SVX8KuOAwW",
    "outputId": "2e7588ed-d0bc-41ed-eaa9-ad1266b08bff"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class ResNetForAnimalRecognition(nn.Module):\n",
    "#     def __init__(self, num_classes=200):\n",
    "#         super().__init__()\n",
    "#         # Load pre-trained ResNet50 from timm\n",
    "#         self.resnet = timm.create_model('resnet50', pretrained=True, num_classes=0)  # num_classes=0 removes final FC layer\n",
    "#         self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # Global Average Pooling\n",
    "#         self.classifier = nn.Linear(2048, num_classes)  # ResNet50 has 2048-dim features\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         features = self.resnet.forward_features(x)  # Extract feature maps\n",
    "#         features = self.global_pool(features)  # Apply Global Average Pooling\n",
    "#         features = torch.flatten(features, 1)  # Flatten to (batch_size, 2048)\n",
    "#         return self.classifier(features)\n",
    "\n",
    "#     def extract_features(self, x):\n",
    "#         \"\"\"Extracts feature embeddings from the ResNet backbone (without classification layer).\"\"\"\n",
    "#         features = self.resnet.forward_features(x)\n",
    "#         features = self.global_pool(features)\n",
    "#         return torch.flatten(features, 1)\n",
    "\n",
    "# # Detect available device (CUDA for Colab, MPS for Mac)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# # Initialize and move model to the device\n",
    "# model = ResNetForAnimalRecognition(num_classes=1072).to(device)\n",
    "\n",
    "# # If using multiple GPUs in Colab, enable DataParallel\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(f\"Using {torch.cuda.device_count()} GPUs for training!\")\n",
    "#     model = nn.DataParallel(model)\n",
    "\n",
    "# print(f\"Model loaded on {device}\")\n",
    "\n",
    "\n",
    "class EfficientNetForAnimalRecognition(nn.Module):\n",
    "    def __init__(self, num_classes=1072):\n",
    "        super().__init__()\n",
    "        # Load pre-trained EfficientNet-B3 from timm\n",
    "        self.efficientnet = timm.create_model('efficientnet_b3', pretrained=True, num_classes=0)  # Removes classifier\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # Global Average Pooling\n",
    "        self.classifier = nn.Linear(1536, num_classes)  # EfficientNet-B3 has 1536-dim feature embeddings\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.efficientnet.forward_features(x)  # Extract feature maps\n",
    "        features = self.global_pool(features)  # Apply Global Average Pooling\n",
    "        features = torch.flatten(features, 1)  # Flatten to (batch_size, 1536)\n",
    "        return self.classifier(features)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        \"\"\"Extracts feature embeddings from the EfficientNet backbone (without classification layer).\"\"\"\n",
    "        features = self.efficientnet.forward_features(x)\n",
    "        features = self.global_pool(features)\n",
    "        return torch.flatten(features, 1)\n",
    "\n",
    "# Detect available device (CUDA for Colab, MPS for Mac)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize and move model to the device\n",
    "model = EfficientNetForAnimalRecognition(num_classes=1072).to(device)\n",
    "\n",
    "# If using multiple GPUs in Colab, enable DataParallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs for training!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "krTKdhK1OFuV"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Ztu4iM1cOJ4x",
    "outputId": "f079e88a-3336-4a30-c848-d57b0d233602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Train Loss: 6.5255 | Val Loss: 5.6510 | Val Acc: 0.1325\n",
      "Epoch 2/15\n",
      "Train Loss: 4.7781 | Val Loss: 3.6753 | Val Acc: 0.4935\n",
      "Epoch 3/15\n",
      "Train Loss: 3.2811 | Val Loss: 2.2988 | Val Acc: 0.7357\n",
      "Epoch 4/15\n",
      "Train Loss: 2.2580 | Val Loss: 1.4178 | Val Acc: 0.8436\n",
      "Epoch 5/15\n",
      "Train Loss: 1.5546 | Val Loss: 0.9211 | Val Acc: 0.8830\n",
      "Epoch 6/15\n",
      "Train Loss: 1.1166 | Val Loss: 0.6434 | Val Acc: 0.9027\n",
      "Epoch 7/15\n",
      "Train Loss: 0.8460 | Val Loss: 0.4891 | Val Acc: 0.9094\n",
      "Epoch 8/15\n",
      "Train Loss: 0.6662 | Val Loss: 0.3735 | Val Acc: 0.9157\n",
      "Epoch 9/15\n",
      "Train Loss: 0.5480 | Val Loss: 0.3096 | Val Acc: 0.9191\n",
      "Epoch 10/15\n",
      "Train Loss: 0.4665 | Val Loss: 0.2686 | Val Acc: 0.9245\n",
      "Epoch 11/15\n",
      "Train Loss: 0.4099 | Val Loss: 0.2427 | Val Acc: 0.9251\n",
      "Epoch 12/15\n",
      "Train Loss: 0.3555 | Val Loss: 0.2202 | Val Acc: 0.9212\n",
      "Epoch 13/15\n",
      "Train Loss: 0.3269 | Val Loss: 0.2048 | Val Acc: 0.9288\n",
      "Epoch 14/15\n",
      "Train Loss: 0.3017 | Val Loss: 0.1858 | Val Acc: 0.9315\n",
      "Epoch 15/15\n",
      "Train Loss: 0.2719 | Val Loss: 0.1815 | Val Acc: 0.9336\n",
      "Best Validation Accuracy: 0.9336\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def train_model(model, num_epochs=10):\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.long()  # âœ… Ensure labels are of type torch.long\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # âœ… Debugging: Check label range\n",
    "            if labels.max() >= outputs.shape[1] or labels.min() < 0:\n",
    "                print(f\"ðŸ”¥ Label out of range! Max: {labels.max()}, Min: {labels.min()}\")\n",
    "                print(f\"Expected range: 0 to {outputs.shape[1]-1}\")\n",
    "                return\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                labels = labels.long()  # âœ… Ensure labels are torch.long\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = correct / total\n",
    "        val_loss = val_loss / len(val_dataset)\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), './best_model.pth')\n",
    "\n",
    "    print(f'Best Validation Accuracy: {best_acc:.4f}')\n",
    "\n",
    "# âœ… Add CUDA debugging environment variable (optional, for debugging)\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "train_model(model, num_epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8DK5e65aOJ_n"
   },
   "outputs": [],
   "source": [
    "def extract_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            features_batch = model.extract_features(inputs)\n",
    "            features.append(features_batch.cpu().numpy())\n",
    "            labels_list.append(labels.numpy())\n",
    "\n",
    "    return np.concatenate(features), np.concatenate(labels_list)\n",
    "\n",
    "# Extract features from training data\n",
    "train_features, train_labels = extract_features(model, train_loader)\n",
    "\n",
    "# Save features\n",
    "np.save('./train_features.npy', train_features)\n",
    "np.save('./train_labels.npy', train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "C7igteU0ONZg",
    "outputId": "7c6d2704-1477-4b96-ce96-2ee97d4dbd31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9285\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {correct / total:.4f}')\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('./best_model.pth'))\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ad049WA_lbjd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
