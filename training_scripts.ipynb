{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Setting TF_USE_LEGACY_KERAS=1. Make sure this is ahead of importing tensorflow or keras.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import losses, train, GhostFaceNets\n",
    "import tensorflow as tf\n",
    "import keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the below for better accuracies and keep it for faster training\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GhostFaceNetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "data_basic_path = 'datasets'  # Adjust this path as necessary\n",
    "data_path = data_basic_path + '_bin'  # Assuming you have your .bin file here\n",
    "\n",
    "# Paths to evaluation datasets\n",
    "eval_paths = [os.path.join(data_basic_path, 'dataset.bin')] \n",
    "\n",
    "# # (MS1MV2) dataset\n",
    "# Main dataset folder (adjust the path if necessary)\n",
    "data_path = 'datasets/dataset'  # Path to your main dataset folder\n",
    "\n",
    "# Paths to evaluation datasets\n",
    "eval_paths = ['datasets/_bin/dataset.bin']\n",
    "\n",
    "\n",
    "data_path_ms1m_v3 = data_basic_path + '_bin'  # MS1M-RetinaFace\n",
    "data_path_ms1m_v2 = 'datasets/dataset'  # MS1M-ArcFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Change BatchNormalization momentum and epsilon default value.\n",
      ">>>> Convert ReLU: activation_480 --> activation_480\n",
      ">>>> Convert ReLU: activation_481 --> activation_481\n",
      ">>>> Convert ReLU: activation_482 --> activation_482\n",
      ">>>> Convert ReLU: activation_483 --> activation_483\n",
      ">>>> Convert ReLU: activation_484 --> activation_484\n",
      ">>>> Convert ReLU: activation_485 --> activation_485\n",
      ">>>> Convert ReLU: activation_486 --> activation_486\n",
      ">>>> Convert ReLU: activation_487 --> activation_487\n",
      ">>>> Convert ReLU: activation_488 --> activation_488\n",
      ">>>> Convert ReLU: activation_489 --> activation_489\n",
      ">>>> Convert ReLU: activation_491 --> activation_491\n",
      ">>>> Convert ReLU: activation_492 --> activation_492\n",
      ">>>> Convert ReLU: activation_493 --> activation_493\n",
      ">>>> Convert ReLU: activation_495 --> activation_495\n",
      ">>>> Convert ReLU: activation_496 --> activation_496\n",
      ">>>> Convert ReLU: activation_497 --> activation_497\n",
      ">>>> Convert ReLU: activation_498 --> activation_498\n",
      ">>>> Convert ReLU: activation_499 --> activation_499\n",
      ">>>> Convert ReLU: activation_500 --> activation_500\n",
      ">>>> Convert ReLU: activation_501 --> activation_501\n",
      ">>>> Convert ReLU: activation_502 --> activation_502\n",
      ">>>> Convert ReLU: activation_503 --> activation_503\n",
      ">>>> Convert ReLU: activation_504 --> activation_504\n",
      ">>>> Convert ReLU: activation_505 --> activation_505\n",
      ">>>> Convert ReLU: activation_507 --> activation_507\n",
      ">>>> Convert ReLU: activation_508 --> activation_508\n",
      ">>>> Convert ReLU: activation_509 --> activation_509\n",
      ">>>> Convert ReLU: activation_511 --> activation_511\n",
      ">>>> Convert ReLU: activation_512 --> activation_512\n",
      ">>>> Convert ReLU: activation_513 --> activation_513\n",
      ">>>> Convert ReLU: activation_515 --> activation_515\n",
      ">>>> Convert ReLU: activation_516 --> activation_516\n",
      ">>>> Convert ReLU: activation_517 --> activation_517\n",
      ">>>> Convert ReLU: activation_518 --> activation_518\n",
      ">>>> Convert ReLU: activation_519 --> activation_519\n",
      ">>>> Convert ReLU: activation_521 --> activation_521\n",
      ">>>> Convert ReLU: activation_522 --> activation_522\n",
      ">>>> Convert ReLU: activation_523 --> activation_523\n",
      ">>>> Convert ReLU: activation_524 --> activation_524\n",
      ">>>> Convert ReLU: activation_525 --> activation_525\n",
      ">>>> Convert ReLU: activation_527 --> activation_527\n",
      ">>>> Change BatchNormalization momentum and epsilon default value.\n",
      ">>>> Convert ReLU: activation_528 --> activation_528\n",
      ">>>> Convert ReLU: activation_529 --> activation_529\n",
      ">>>> Convert ReLU: activation_530 --> activation_530\n",
      ">>>> Convert ReLU: activation_531 --> activation_531\n",
      ">>>> Convert ReLU: activation_532 --> activation_532\n",
      ">>>> Convert ReLU: activation_533 --> activation_533\n",
      ">>>> Convert ReLU: activation_534 --> activation_534\n",
      ">>>> Convert ReLU: activation_535 --> activation_535\n",
      ">>>> Convert ReLU: activation_536 --> activation_536\n",
      ">>>> Convert ReLU: activation_537 --> activation_537\n",
      ">>>> Convert ReLU: activation_539 --> activation_539\n",
      ">>>> Convert ReLU: activation_540 --> activation_540\n",
      ">>>> Convert ReLU: activation_541 --> activation_541\n",
      ">>>> Convert ReLU: activation_543 --> activation_543\n",
      ">>>> Convert ReLU: activation_544 --> activation_544\n",
      ">>>> Convert ReLU: activation_545 --> activation_545\n",
      ">>>> Convert ReLU: activation_546 --> activation_546\n",
      ">>>> Convert ReLU: activation_547 --> activation_547\n",
      ">>>> Convert ReLU: activation_548 --> activation_548\n",
      ">>>> Convert ReLU: activation_549 --> activation_549\n",
      ">>>> Convert ReLU: activation_550 --> activation_550\n",
      ">>>> Convert ReLU: activation_551 --> activation_551\n",
      ">>>> Convert ReLU: activation_552 --> activation_552\n",
      ">>>> Convert ReLU: activation_553 --> activation_553\n",
      ">>>> Convert ReLU: activation_555 --> activation_555\n",
      ">>>> Convert ReLU: activation_556 --> activation_556\n",
      ">>>> Convert ReLU: activation_557 --> activation_557\n",
      ">>>> Convert ReLU: activation_559 --> activation_559\n",
      ">>>> Convert ReLU: activation_560 --> activation_560\n",
      ">>>> Convert ReLU: activation_561 --> activation_561\n",
      ">>>> Convert ReLU: activation_563 --> activation_563\n",
      ">>>> Convert ReLU: activation_564 --> activation_564\n",
      ">>>> Convert ReLU: activation_565 --> activation_565\n",
      ">>>> Convert ReLU: activation_566 --> activation_566\n",
      ">>>> Convert ReLU: activation_567 --> activation_567\n",
      ">>>> Convert ReLU: activation_569 --> activation_569\n",
      ">>>> Convert ReLU: activation_570 --> activation_570\n",
      ">>>> Convert ReLU: activation_571 --> activation_571\n",
      ">>>> Convert ReLU: activation_572 --> activation_572\n",
      ">>>> Convert ReLU: activation_573 --> activation_573\n",
      ">>>> Convert ReLU: activation_575 --> activation_575\n"
     ]
    }
   ],
   "source": [
    "# #GhostFaceNetV1\n",
    "# # Strides of 2\n",
    "# basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "# basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "# basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# # Strides of 1\n",
    "# basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "# basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "# basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# GhostFaceNetV1 for Strides of 2\n",
    "basic_model_s2 = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model_s2 = GhostFaceNets.add_l2_regularizer_2_model(basic_model_s2, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model_s2 = GhostFaceNets.replace_ReLU_with_PReLU(basic_model_s2)\n",
    "\n",
    "# GhostFaceNetV1 for Strides of 1\n",
    "basic_model_s1 = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model_s1 = GhostFaceNets.add_l2_regularizer_2_model(basic_model_s1, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model_s1 = GhostFaceNets.replace_ReLU_with_PReLU(basic_model_s1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> L2 regularizer value from basic_model: 0.00025\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/niteshkumar/Documents/BTP/GhostFaceNets/evals.py\", line 25, in None  *\n        lambda xx: (tf.cast(tf.image.decode_image(tf.io.read_file(xx), channels=3), \"float32\") - 127.5) * 0.0078125\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# # Strides of 2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# tt = train.Train(data_path, eval_paths=eval_paths,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     save_path='ghostnetv1_w1.3_s2.h5',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Strides of 2\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m tt_s2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path_ms1m_v3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mghostnetv1_w1.3_s2.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbasic_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasic_model_s2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_decay_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Strides of 1\u001b[39;00m\n\u001b[1;32m     20\u001b[0m tt_s1 \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mTrain(data_path_ms1m_v2, eval_paths\u001b[38;5;241m=\u001b[39meval_paths,\n\u001b[1;32m     21\u001b[0m     save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mghostnetv1_w1.3_s1.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m     basic_model\u001b[38;5;241m=\u001b[39mbasic_model_s1, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lr_base\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, lr_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, lr_decay_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m, lr_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,\n\u001b[1;32m     23\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, random_status\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, eval_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, output_weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/BTP/GhostFaceNets/train.py:134\u001b[0m, in \u001b[0;36mTrain.__init__\u001b[0;34m(self, data_path, save_path, eval_paths, basic_model, model, compile, output_weight_decay, custom_objects, pretrained, batch_size, lr_base, lr_decay, lr_decay_steps, lr_min, lr_warmup_steps, eval_freq, random_status, random_cutout_mask_area, image_per_class, samples_per_mining, mixup_alpha, partial_fc_split, teacher_model_interf, sam_rho, vpl_start_iters, vpl_allowed_delta)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_options\u001b[38;5;241m.\u001b[39mexperimental_distribute\u001b[38;5;241m.\u001b[39mauto_shard_policy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAutoShardPolicy\u001b[38;5;241m.\u001b[39mDATA\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#Evaluate\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m my_evals \u001b[38;5;241m=\u001b[39m [evals\u001b[38;5;241m.\u001b[39meval_callback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_model, ii, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size_per_replica, eval_freq\u001b[38;5;241m=\u001b[39meval_freq) \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m eval_paths]\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(my_evals) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    136\u001b[0m     my_evals[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msave_model \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(save_path)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/BTP/GhostFaceNets/train.py:134\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_options\u001b[38;5;241m.\u001b[39mexperimental_distribute\u001b[38;5;241m.\u001b[39mauto_shard_policy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAutoShardPolicy\u001b[38;5;241m.\u001b[39mDATA\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#Evaluate\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m my_evals \u001b[38;5;241m=\u001b[39m [\u001b[43mevals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mii\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size_per_replica\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m eval_paths]\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(my_evals) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    136\u001b[0m     my_evals[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msave_model \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(save_path)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/BTP/GhostFaceNets/evals.py:26\u001b[0m, in \u001b[0;36meval_callback.__init__\u001b[0;34m(self, basic_model, test_bin_file, batch_size, save_model, eval_freq, flip, PCA_acc)\u001b[0m\n\u001b[1;32m     24\u001b[0m ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(bins)\n\u001b[1;32m     25\u001b[0m _imread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m xx: (tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_image(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_file(xx), channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m127.5\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.0078125\u001b[39m\n\u001b[0;32m---> 26\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_imread\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mbatch(batch_size)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_issame \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(issame_list)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2311\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2308\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2309\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2310\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2312\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1251\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1250\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1221\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1225\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/q1/_jp_f57920s2n_hjw96hnnkh0000gn/T/__autograph_generated_file9yjo_p4r.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[0;34m(xx)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n\u001b[0;32m----> 5\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m xx: \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_function_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m127.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0078125\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlscope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/core/function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[0;34m(thunk, scope_name, options)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_\u001b[39m\u001b[38;5;124m'\u001b[39m, scope_name, options) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[0;32m--> 113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/folders/q1/_jp_f57920s2n_hjw96hnnkh0000gn/T/__autograph_generated_file9yjo_p4r.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[0;34m(lscope)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n\u001b[0;32m----> 5\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m xx: ag__\u001b[38;5;241m.\u001b[39mwith_function_scope(\u001b[38;5;28;01mlambda\u001b[39;00m lscope: (ag__\u001b[38;5;241m.\u001b[39mconverted_call(tf\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_image, (\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m,), \u001b[38;5;28mdict\u001b[39m(channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m), lscope), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, lscope) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m127.5\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.0078125\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mSTD)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/ops/io_ops.py:134\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.read_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.read_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(filename, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the contents of file.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m  This operation returns a tensor with the entire contents of the input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    A tensor of dtype \"string\", with the file contents.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_io_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py:588\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadFile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:778\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mas_default(), ops\u001b[38;5;241m.\u001b[39mname_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[1;32m    777\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[0;32m--> 778\u001b[0m     \u001b[43m_ExtractInputsAndAttrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_list_attr_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_type_attr_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m                           \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    782\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    783\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:578\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    575\u001b[0m prefix \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Op has type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m that does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    576\u001b[0m           (input_name, op_type_name, observed))\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_arg\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m types_pb2\u001b[38;5;241m.\u001b[39mDT_INVALID:\n\u001b[0;32m--> 578\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected type of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtypes\u001b[38;5;241m.\u001b[39mas_dtype(input_arg\u001b[38;5;241m.\u001b[39mtype)\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m   \u001b[38;5;66;03m# Update the maps with the default, if needed.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m   k \u001b[38;5;241m=\u001b[39m input_arg\u001b[38;5;241m.\u001b[39mtype_attr\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/niteshkumar/Documents/BTP/GhostFaceNets/evals.py\", line 25, in None  *\n        lambda xx: (tf.cast(tf.image.decode_image(tf.io.read_file(xx), channels=3), \"float32\") - 127.5) * 0.0078125\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n"
     ]
    }
   ],
   "source": [
    "# # Strides of 2\n",
    "# tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "#     save_path='ghostnetv1_w1.3_s2.h5',\n",
    "#     basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "#     batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# # Strides of 1\n",
    "# tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "#     save_path='ghostnetv1_w1.3_s1.h5',\n",
    "#     basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "#     batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# Strides of 2\n",
    "tt_s2 = train.Train(data_path_ms1m_v3, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2.h5',\n",
    "    basic_model=basic_model_s2, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# Strides of 1\n",
    "tt_s1 = train.Train(data_path_ms1m_v2, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1.h5',\n",
    "    basic_model=basic_model_s1, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GhostFaceNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "data_path = data_basic_path + '_112x112_folders'\n",
    "eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/faces_emore_112x112_folders'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CosFaceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.CosFaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.CosFaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subcenter ArcFace Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "data_path = data_basic_path + '_112x112_folders'\n",
    "eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/faces_emore_112x112_folders'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GhostFaceNetV1\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GhostFaceNetV2\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" First, Train with `lossTopK = 3` \"\"\"\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer, \"lossTopK\": 3},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50, \"lossTopK\": 3},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Then drop non-dominant subcenters and high-confident noisy data, which is `>75 degrees` \"\"\"\n",
    "import data_drop_top_k\n",
    "# data_drop_top_k.data_drop_top_k('./checkpoints/TT_mobilenet_topk_bs256.h5', '/datasets/faces_casia_112x112_folders/', limit=20)\n",
    "new_data_path = data_drop_top_k.data_drop_top_k(tt.model, tt.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train with the new dataset again, this time `lossTopK = 1` \"\"\"\n",
    "tt.reset_dataset(new_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you can continue training the model or start training again and considering the generated dataset as a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models from scatch using the new generated dataset\n",
    "\n",
    "# New Cleaned Dataset\n",
    "data_path = 'Path_To_New_Generated_Dataset'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
