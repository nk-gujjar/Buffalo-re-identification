{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras_cv_attention_models\n",
    "#!pip install --upgrade tensorflow keras numpy\n",
    "# !pip install numpy==1.24 tensorflow==2.17\n",
    "\n",
    "# !pip uninstall tensorflow\n",
    "# !pip install tensorflow==2.13.0  # or use the specific version you're working with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Setting TF_USE_LEGACY_KERAS=1. Make sure this is ahead of importing tensorflow or keras.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import losses, train, GhostFaceNets\n",
    "import tensorflow as tf\n",
    "import keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "# Remove the below for better accuracies and keep it for faster training\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GhostFaceNetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "# data_basic_path = 'datasets'  # Adjust this path as necessary\n",
    "# data_path = data_basic_path + '_bin'  # Assuming you have your .bin file here\n",
    "\n",
    "# # Paths to evaluation datasets\n",
    "# eval_paths = [os.path.join(data_basic_path, 'dataset.bin')] \n",
    "\n",
    "# # # (MS1MV2) dataset\n",
    "# # Main dataset folder (adjust the path if necessary)\n",
    "# data_path = 'datasets/dataset'  # Path to your main dataset folder\n",
    "\n",
    "# # Paths to evaluation datasets\n",
    "# eval_paths = ['datasets/_bin/dataset.bin']\n",
    "\n",
    "\n",
    "# data_path_ms1m_v3 = data_basic_path + '_bin'  # MS1M-RetinaFace\n",
    "# data_path_ms1m_v2 = 'datasets/dataset'  # MS1M-ArcFace\n",
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "data_path = data_basic_path + '_112x112_folders'\n",
    "eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/faces_emore_112x112_folders'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteshkumar/conda/envs/tf_env/lib/python3.9/site-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Change BatchNormalization momentum and epsilon default value.\n",
      ">>>> Convert ReLU: activation --> activation\n",
      ">>>> Convert ReLU: activation_1 --> activation_1\n",
      ">>>> Convert ReLU: activation_2 --> activation_2\n",
      ">>>> Convert ReLU: activation_3 --> activation_3\n",
      ">>>> Convert ReLU: activation_4 --> activation_4\n",
      ">>>> Convert ReLU: activation_5 --> activation_5\n",
      ">>>> Convert ReLU: activation_6 --> activation_6\n",
      ">>>> Convert ReLU: activation_7 --> activation_7\n",
      ">>>> Convert ReLU: activation_8 --> activation_8\n",
      ">>>> Convert ReLU: activation_9 --> activation_9\n",
      ">>>> Convert ReLU: activation_11 --> activation_11\n",
      ">>>> Convert ReLU: activation_12 --> activation_12\n",
      ">>>> Convert ReLU: activation_13 --> activation_13\n",
      ">>>> Convert ReLU: activation_15 --> activation_15\n",
      ">>>> Convert ReLU: activation_16 --> activation_16\n",
      ">>>> Convert ReLU: activation_17 --> activation_17\n",
      ">>>> Convert ReLU: activation_18 --> activation_18\n",
      ">>>> Convert ReLU: activation_19 --> activation_19\n",
      ">>>> Convert ReLU: activation_20 --> activation_20\n",
      ">>>> Convert ReLU: activation_21 --> activation_21\n",
      ">>>> Convert ReLU: activation_22 --> activation_22\n",
      ">>>> Convert ReLU: activation_23 --> activation_23\n",
      ">>>> Convert ReLU: activation_24 --> activation_24\n",
      ">>>> Convert ReLU: activation_25 --> activation_25\n",
      ">>>> Convert ReLU: activation_27 --> activation_27\n",
      ">>>> Convert ReLU: activation_28 --> activation_28\n",
      ">>>> Convert ReLU: activation_29 --> activation_29\n",
      ">>>> Convert ReLU: activation_31 --> activation_31\n",
      ">>>> Convert ReLU: activation_32 --> activation_32\n",
      ">>>> Convert ReLU: activation_33 --> activation_33\n",
      ">>>> Convert ReLU: activation_35 --> activation_35\n",
      ">>>> Convert ReLU: activation_36 --> activation_36\n",
      ">>>> Convert ReLU: activation_37 --> activation_37\n",
      ">>>> Convert ReLU: activation_38 --> activation_38\n",
      ">>>> Convert ReLU: activation_39 --> activation_39\n",
      ">>>> Convert ReLU: activation_41 --> activation_41\n",
      ">>>> Convert ReLU: activation_42 --> activation_42\n",
      ">>>> Convert ReLU: activation_43 --> activation_43\n",
      ">>>> Convert ReLU: activation_44 --> activation_44\n",
      ">>>> Convert ReLU: activation_45 --> activation_45\n",
      ">>>> Convert ReLU: activation_47 --> activation_47\n",
      ">>>> Change BatchNormalization momentum and epsilon default value.\n",
      ">>>> Convert ReLU: activation_48 --> activation_48\n",
      ">>>> Convert ReLU: activation_49 --> activation_49\n",
      ">>>> Convert ReLU: activation_50 --> activation_50\n",
      ">>>> Convert ReLU: activation_51 --> activation_51\n",
      ">>>> Convert ReLU: activation_52 --> activation_52\n",
      ">>>> Convert ReLU: activation_53 --> activation_53\n",
      ">>>> Convert ReLU: activation_54 --> activation_54\n",
      ">>>> Convert ReLU: activation_55 --> activation_55\n",
      ">>>> Convert ReLU: activation_56 --> activation_56\n",
      ">>>> Convert ReLU: activation_57 --> activation_57\n",
      ">>>> Convert ReLU: activation_59 --> activation_59\n",
      ">>>> Convert ReLU: activation_60 --> activation_60\n",
      ">>>> Convert ReLU: activation_61 --> activation_61\n",
      ">>>> Convert ReLU: activation_63 --> activation_63\n",
      ">>>> Convert ReLU: activation_64 --> activation_64\n",
      ">>>> Convert ReLU: activation_65 --> activation_65\n",
      ">>>> Convert ReLU: activation_66 --> activation_66\n",
      ">>>> Convert ReLU: activation_67 --> activation_67\n",
      ">>>> Convert ReLU: activation_68 --> activation_68\n",
      ">>>> Convert ReLU: activation_69 --> activation_69\n",
      ">>>> Convert ReLU: activation_70 --> activation_70\n",
      ">>>> Convert ReLU: activation_71 --> activation_71\n",
      ">>>> Convert ReLU: activation_72 --> activation_72\n",
      ">>>> Convert ReLU: activation_73 --> activation_73\n",
      ">>>> Convert ReLU: activation_75 --> activation_75\n",
      ">>>> Convert ReLU: activation_76 --> activation_76\n",
      ">>>> Convert ReLU: activation_77 --> activation_77\n",
      ">>>> Convert ReLU: activation_79 --> activation_79\n",
      ">>>> Convert ReLU: activation_80 --> activation_80\n",
      ">>>> Convert ReLU: activation_81 --> activation_81\n",
      ">>>> Convert ReLU: activation_83 --> activation_83\n",
      ">>>> Convert ReLU: activation_84 --> activation_84\n",
      ">>>> Convert ReLU: activation_85 --> activation_85\n",
      ">>>> Convert ReLU: activation_86 --> activation_86\n",
      ">>>> Convert ReLU: activation_87 --> activation_87\n",
      ">>>> Convert ReLU: activation_89 --> activation_89\n",
      ">>>> Convert ReLU: activation_90 --> activation_90\n",
      ">>>> Convert ReLU: activation_91 --> activation_91\n",
      ">>>> Convert ReLU: activation_92 --> activation_92\n",
      ">>>> Convert ReLU: activation_93 --> activation_93\n",
      ">>>> Convert ReLU: activation_95 --> activation_95\n"
     ]
    }
   ],
   "source": [
    "# #GhostFaceNetV1\n",
    "# # Strides of 2\n",
    "# basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "# basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "# basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# # Strides of 1\n",
    "# basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "# basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "# basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "#GhostFaceNetV1\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> L2 regularizer value from basic_model: 0.00025\n",
      "abc edvhwjdbf :\n",
      "abc edvhwjdbf :\n",
      "abc edvhwjdbf :\n",
      ">>>> L2 regularizer value from basic_model: 0.00025\n",
      "abc edvhwjdbf :\n",
      "abc edvhwjdbf :\n",
      "abc edvhwjdbf :\n"
     ]
    }
   ],
   "source": [
    "# # Strides of 2\n",
    "# tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "#     save_path='ghostnetv1_w1.3_s2.h5',\n",
    "#     basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "#     batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# # Strides of 1\n",
    "# tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "#     save_path='ghostnetv1_w1.3_s1.h5',\n",
    "#     basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "#     batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2.weights.h5',  # Updated here\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1.weights.h5',  # Updated here\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Init type by loss function name...\n",
      ">>>> Train arcface...\n",
      ">>>> Init softmax dataset...\n",
      ">>>> reloaded from dataset backup: faces_emore_112x112_folders_shuffle.npz\n",
      ">>>> Image length: 100, Image class length: 100, classes: 10\n",
      ">>>> Add L2 regularizer to model output layer, output_weight_decay = 0.000500\n",
      ">>>> Add arcface layer, arc_kwargs={'loss_top_k': 1, 'append_norm': False, 'partial_fc_split': 0, 'name': 'arcface'}, vpl_kwargs={'vpl_lambda': 0.15, 'start_iters': 0, 'allowed_delta': 200}...\n",
      ">>>> loss_weights: {'arcface': 1}\n",
      "\n",
      "Epoch 1: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 00:35:44.538905: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/niteshkumar/conda/envs/tf_env/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Train arcface DONE!!! epochs = [0], model.stop_training = False\n",
      ">>>> My history:\n",
      "{\n",
      "}\n",
      ">>>> Saving latest basic model to: checkpoints/ghostnetv1_w1.3_s1.weights_basic_model_latest.h5\n",
      ">>>> Init type by loss function name...\n",
      ">>>> Train arcface...\n",
      ">>>> Add L2 regularizer to model output layer, output_weight_decay = 0.000500\n",
      ">>>> Will NOT change model output layer.\n",
      ">>>> loss_weights: {'arcface': 1}\n",
      "Epoch 2/51\n",
      "\n",
      "Epoch 2: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 00:35:59.131994: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 0s/step\n",
      "Epoch 3/51\n",
      "\n",
      "Epoch 3: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0s/step\n",
      "Epoch 4/51\n",
      "\n",
      "Epoch 4: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 5/51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 00:36:04.474317: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0s/step\n",
      "Epoch 6/51\n",
      "\n",
      "Epoch 6: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0s/step\n",
      "Epoch 7/51\n",
      "\n",
      "Epoch 7: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0s/step\n",
      "Epoch 8/51\n",
      "\n",
      "Epoch 8: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 9/51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 00:36:14.848831: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 10/51\n",
      "\n",
      "Epoch 10: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 11/51\n",
      "\n",
      "Epoch 11: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 12/51\n",
      "\n",
      "Epoch 12: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 13/51\n",
      "\n",
      "Epoch 13: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 14/51\n",
      "\n",
      "Epoch 14: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0s/step\n",
      "Epoch 15/51\n",
      "\n",
      "Epoch 15: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0s/step\n",
      "Epoch 16/51\n",
      "\n",
      "Epoch 16: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0s/step\n",
      "Epoch 17/51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 00:36:34.808809: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 18/51\n",
      "\n",
      "Epoch 18: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 19/51\n",
      "\n",
      "Epoch 19: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 20/51\n",
      "\n",
      "Epoch 20: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 21/51\n",
      "\n",
      "Epoch 21: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 22/51\n",
      "\n",
      "Epoch 22: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 23/51\n",
      "\n",
      "Epoch 23: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 24/51\n",
      "\n",
      "Epoch 24: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 25/51\n",
      "\n",
      "Epoch 25: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 26/51\n",
      "\n",
      "Epoch 26: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0s/step\n",
      "Epoch 27/51\n",
      "\n",
      "Epoch 27: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 28/51\n",
      "\n",
      "Epoch 28: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 29/51\n",
      "\n",
      "Epoch 29: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 30/51\n",
      "\n",
      "Epoch 30: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 31/51\n",
      "\n",
      "Epoch 31: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 32/51\n",
      "\n",
      "Epoch 32: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 00:37:10.173315: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/51\n",
      "\n",
      "Epoch 33: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 34/51\n",
      "\n",
      "Epoch 34: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 35/51\n",
      "\n",
      "Epoch 35: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 36/51\n",
      "\n",
      "Epoch 36: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0s/step\n",
      "Epoch 37/51\n",
      "\n",
      "Epoch 37: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 38/51\n",
      "\n",
      "Epoch 38: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 39/51\n",
      "\n",
      "Epoch 39: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 40/51\n",
      "\n",
      "Epoch 40: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 41/51\n",
      "\n",
      "Epoch 41: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 42/51\n",
      "\n",
      "Epoch 42: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 43/51\n",
      "\n",
      "Epoch 43: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 44/51\n",
      "\n",
      "Epoch 44: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 45/51\n",
      "\n",
      "Epoch 45: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 46/51\n",
      "\n",
      "Epoch 46: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 47/51\n",
      "\n",
      "Epoch 47: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 48/51\n",
      "\n",
      "Epoch 48: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 49/51\n",
      "\n",
      "Epoch 49: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 50/51\n",
      "\n",
      "Epoch 50: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n",
      "Epoch 51/51\n",
      "\n",
      "Epoch 51: saving model to checkpoints/ghostnetv1_w1.3_s1.weights.weights.h5\n",
      "\u001b[1m0/1\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Train arcface DONE!!! epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], model.stop_training = False\n",
      ">>>> My history:\n",
      "{\n",
      "}\n",
      ">>>> Saving latest basic model to: checkpoints/ghostnetv1_w1.3_s1.weights_basic_model_latest.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "# sch = [\n",
    "#     {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "#     {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50, \"optimizer\": optimizer},\n",
    "# ]\n",
    "# tt.train(sch, 0)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": \"SGD\"},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50, \"optimizer\": \"SGD\"},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GhostFaceNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "data_path = data_basic_path + '_112x112_folders'\n",
    "eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/faces_emore_112x112_folders'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution), but are not present in its tracked objects:   <tf.Variable 'stem_conv/kernel:0' shape=(3, 3, 3, 20) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution), but are not present in its tracked objects:   <tf.Variable 'stem_conv/kernel:0' shape=(3, 3, 3, 20) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_1), but are not present in its tracked objects:   <tf.Variable 'stack1_ghost_1_prim_conv/kernel:0' shape=(1, 1, 20, 10) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_1), but are not present in its tracked objects:   <tf.Variable 'stack1_ghost_1_prim_conv/kernel:0' shape=(1, 1, 20, 10) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d), but are not present in its tracked objects:   <tf.Variable 'stack1_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 10, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d), but are not present in its tracked objects:   <tf.Variable 'stack1_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 10, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_2), but are not present in its tracked objects:   <tf.Variable 'stack1_ghost_2_prim_conv/kernel:0' shape=(1, 1, 20, 10) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_2), but are not present in its tracked objects:   <tf.Variable 'stack1_ghost_2_prim_conv/kernel:0' shape=(1, 1, 20, 10) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_1), but are not present in its tracked objects:   <tf.Variable 'stack1_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 10, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_1), but are not present in its tracked objects:   <tf.Variable 'stack1_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 10, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_2), but are not present in its tracked objects:   <tf.Variable 'stack2_short_1_dw_conv/kernel:0' shape=(3, 3, 20, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_2), but are not present in its tracked objects:   <tf.Variable 'stack2_short_1_dw_conv/kernel:0' shape=(3, 3, 20, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_3), but are not present in its tracked objects:   <tf.Variable 'stack2_short_2_conv/kernel:0' shape=(1, 1, 20, 32) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_3), but are not present in its tracked objects:   <tf.Variable 'stack2_short_2_conv/kernel:0' shape=(1, 1, 20, 32) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_4), but are not present in its tracked objects:   <tf.Variable 'stack2_ghost_1_prim_conv/kernel:0' shape=(1, 1, 20, 32) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_4), but are not present in its tracked objects:   <tf.Variable 'stack2_ghost_1_prim_conv/kernel:0' shape=(1, 1, 20, 32) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_3), but are not present in its tracked objects:   <tf.Variable 'stack2_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 32, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_3), but are not present in its tracked objects:   <tf.Variable 'stack2_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 32, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_4), but are not present in its tracked objects:   <tf.Variable 'stack2_down_dw_conv/kernel:0' shape=(3, 3, 64, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_4), but are not present in its tracked objects:   <tf.Variable 'stack2_down_dw_conv/kernel:0' shape=(3, 3, 64, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_5), but are not present in its tracked objects:   <tf.Variable 'stack2_ghost_2_prim_conv/kernel:0' shape=(1, 1, 64, 16) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_5), but are not present in its tracked objects:   <tf.Variable 'stack2_ghost_2_prim_conv/kernel:0' shape=(1, 1, 64, 16) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_5), but are not present in its tracked objects:   <tf.Variable 'stack2_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 16, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_5), but are not present in its tracked objects:   <tf.Variable 'stack2_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 16, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_6), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_1_prim_conv/kernel:0' shape=(1, 1, 32, 46) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_6), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_1_prim_conv/kernel:0' shape=(1, 1, 32, 46) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_6), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 46, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_6), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 46, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_7), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 32, 92) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_7), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 32, 92) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_7), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 92, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_7), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 92, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_8), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 92, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_8), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 92, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_8), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_2_prim_conv/kernel:0' shape=(1, 1, 92, 16) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_8), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_2_prim_conv/kernel:0' shape=(1, 1, 92, 16) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_9), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 16, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_9), but are not present in its tracked objects:   <tf.Variable 'stack3_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 16, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_10), but are not present in its tracked objects:   <tf.Variable 'stack4_short_1_dw_conv/kernel:0' shape=(5, 5, 32, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_10), but are not present in its tracked objects:   <tf.Variable 'stack4_short_1_dw_conv/kernel:0' shape=(5, 5, 32, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_9), but are not present in its tracked objects:   <tf.Variable 'stack4_short_2_conv/kernel:0' shape=(1, 1, 32, 52) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_9), but are not present in its tracked objects:   <tf.Variable 'stack4_short_2_conv/kernel:0' shape=(1, 1, 32, 52) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_10), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_1_prim_conv/kernel:0' shape=(1, 1, 32, 46) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_10), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_1_prim_conv/kernel:0' shape=(1, 1, 32, 46) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_11), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 46, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_11), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 46, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_11), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 32, 92) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_11), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 32, 92) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_12), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 92, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_12), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 92, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_13), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 92, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_13), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 92, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_14), but are not present in its tracked objects:   <tf.Variable 'stack4_down_dw_conv/kernel:0' shape=(5, 5, 92, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_14), but are not present in its tracked objects:   <tf.Variable 'stack4_down_dw_conv/kernel:0' shape=(5, 5, 92, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_12), but are not present in its tracked objects:   <tf.Variable 'stack4_se_1_conv/kernel:0' shape=(1, 1, 92, 24) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_12), but are not present in its tracked objects:   <tf.Variable 'stack4_se_1_conv/kernel:0' shape=(1, 1, 92, 24) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_13), but are not present in its tracked objects:   <tf.Variable 'stack4_se_2_conv/kernel:0' shape=(1, 1, 24, 92) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_13), but are not present in its tracked objects:   <tf.Variable 'stack4_se_2_conv/kernel:0' shape=(1, 1, 24, 92) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_14), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_2_prim_conv/kernel:0' shape=(1, 1, 92, 26) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_14), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_2_prim_conv/kernel:0' shape=(1, 1, 92, 26) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_15), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 26, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_15), but are not present in its tracked objects:   <tf.Variable 'stack4_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 26, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_15), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_1_prim_conv/kernel:0' shape=(1, 1, 52, 78) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_15), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_1_prim_conv/kernel:0' shape=(1, 1, 52, 78) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_16), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 78, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_16), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 78, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_16), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 52, 156) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_16), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 52, 156) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_17), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 156, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_17), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 156, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_18), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 156, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_18), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 156, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_17), but are not present in its tracked objects:   <tf.Variable 'stack5_se_1_conv/kernel:0' shape=(1, 1, 156, 40) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_17), but are not present in its tracked objects:   <tf.Variable 'stack5_se_1_conv/kernel:0' shape=(1, 1, 156, 40) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_18), but are not present in its tracked objects:   <tf.Variable 'stack5_se_2_conv/kernel:0' shape=(1, 1, 40, 156) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_18), but are not present in its tracked objects:   <tf.Variable 'stack5_se_2_conv/kernel:0' shape=(1, 1, 40, 156) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_19), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_2_prim_conv/kernel:0' shape=(1, 1, 156, 26) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_19), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_2_prim_conv/kernel:0' shape=(1, 1, 156, 26) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_19), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 26, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_19), but are not present in its tracked objects:   <tf.Variable 'stack5_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 26, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_20), but are not present in its tracked objects:   <tf.Variable 'stack6_short_1_dw_conv/kernel:0' shape=(3, 3, 52, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_20), but are not present in its tracked objects:   <tf.Variable 'stack6_short_1_dw_conv/kernel:0' shape=(3, 3, 52, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_20), but are not present in its tracked objects:   <tf.Variable 'stack6_short_2_conv/kernel:0' shape=(1, 1, 52, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_20), but are not present in its tracked objects:   <tf.Variable 'stack6_short_2_conv/kernel:0' shape=(1, 1, 52, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_21), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_1_prim_conv/kernel:0' shape=(1, 1, 52, 156) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_21), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_1_prim_conv/kernel:0' shape=(1, 1, 52, 156) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_21), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 156, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_21), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 156, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_22), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 52, 312) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_22), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 52, 312) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_22), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 312, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_22), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 312, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_23), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 312, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_23), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 312, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_24), but are not present in its tracked objects:   <tf.Variable 'stack6_down_dw_conv/kernel:0' shape=(3, 3, 312, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_24), but are not present in its tracked objects:   <tf.Variable 'stack6_down_dw_conv/kernel:0' shape=(3, 3, 312, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_23), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_2_prim_conv/kernel:0' shape=(1, 1, 312, 52) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_23), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_2_prim_conv/kernel:0' shape=(1, 1, 312, 52) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_25), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 52, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_25), but are not present in its tracked objects:   <tf.Variable 'stack6_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 52, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_24), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_1_prim_conv/kernel:0' shape=(1, 1, 104, 130) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_24), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_1_prim_conv/kernel:0' shape=(1, 1, 104, 130) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_26), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 130, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_26), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 130, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_25), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 104, 260) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_25), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 104, 260) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_27), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 260, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_27), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 260, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_28), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 260, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_28), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 260, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_26), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_2_prim_conv/kernel:0' shape=(1, 1, 260, 52) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_26), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_2_prim_conv/kernel:0' shape=(1, 1, 260, 52) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_29), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 52, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_29), but are not present in its tracked objects:   <tf.Variable 'stack7_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 52, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_27), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_1_prim_conv/kernel:0' shape=(1, 1, 104, 120) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_27), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_1_prim_conv/kernel:0' shape=(1, 1, 104, 120) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_30), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 120, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_30), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 120, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_28), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 104, 240) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_28), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 104, 240) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_31), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 240, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_31), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 240, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_32), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 240, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_32), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 240, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_29), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_2_prim_conv/kernel:0' shape=(1, 1, 240, 52) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_29), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_2_prim_conv/kernel:0' shape=(1, 1, 240, 52) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_33), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 52, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_33), but are not present in its tracked objects:   <tf.Variable 'stack8_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 52, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_30), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_1_prim_conv/kernel:0' shape=(1, 1, 104, 120) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_30), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_1_prim_conv/kernel:0' shape=(1, 1, 104, 120) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_34), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 120, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_34), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 120, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_31), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 104, 240) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_31), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 104, 240) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_35), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 240, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_35), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 240, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_36), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 240, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_36), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 240, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_32), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_2_prim_conv/kernel:0' shape=(1, 1, 240, 52) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_32), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_2_prim_conv/kernel:0' shape=(1, 1, 240, 52) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_37), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 52, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_37), but are not present in its tracked objects:   <tf.Variable 'stack9_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 52, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_38), but are not present in its tracked objects:   <tf.Variable 'stack10_short_1_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_38), but are not present in its tracked objects:   <tf.Variable 'stack10_short_1_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_33), but are not present in its tracked objects:   <tf.Variable 'stack10_short_2_conv/kernel:0' shape=(1, 1, 104, 144) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_33), but are not present in its tracked objects:   <tf.Variable 'stack10_short_2_conv/kernel:0' shape=(1, 1, 104, 144) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_34), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_1_prim_conv/kernel:0' shape=(1, 1, 104, 312) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_34), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_1_prim_conv/kernel:0' shape=(1, 1, 104, 312) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_39), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 312, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_39), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 312, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_35), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 104, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_35), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 104, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_40), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_40), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_41), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_41), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_36), but are not present in its tracked objects:   <tf.Variable 'stack10_se_1_conv/kernel:0' shape=(1, 1, 624, 156) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_36), but are not present in its tracked objects:   <tf.Variable 'stack10_se_1_conv/kernel:0' shape=(1, 1, 624, 156) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_37), but are not present in its tracked objects:   <tf.Variable 'stack10_se_2_conv/kernel:0' shape=(1, 1, 156, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_37), but are not present in its tracked objects:   <tf.Variable 'stack10_se_2_conv/kernel:0' shape=(1, 1, 156, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_38), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_2_prim_conv/kernel:0' shape=(1, 1, 624, 72) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_38), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_2_prim_conv/kernel:0' shape=(1, 1, 624, 72) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_42), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 72, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_42), but are not present in its tracked objects:   <tf.Variable 'stack10_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 72, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_39), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_1_prim_conv/kernel:0' shape=(1, 1, 144, 436) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_39), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_1_prim_conv/kernel:0' shape=(1, 1, 144, 436) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_43), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 436, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_43), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 436, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_40), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 144, 872) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_40), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 144, 872) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_44), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 872, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_44), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 872, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_45), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 872, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_45), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 872, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_41), but are not present in its tracked objects:   <tf.Variable 'stack11_se_1_conv/kernel:0' shape=(1, 1, 872, 220) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_41), but are not present in its tracked objects:   <tf.Variable 'stack11_se_1_conv/kernel:0' shape=(1, 1, 872, 220) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_42), but are not present in its tracked objects:   <tf.Variable 'stack11_se_2_conv/kernel:0' shape=(1, 1, 220, 872) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_42), but are not present in its tracked objects:   <tf.Variable 'stack11_se_2_conv/kernel:0' shape=(1, 1, 220, 872) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_43), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_2_prim_conv/kernel:0' shape=(1, 1, 872, 72) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_43), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_2_prim_conv/kernel:0' shape=(1, 1, 872, 72) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_46), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 72, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_46), but are not present in its tracked objects:   <tf.Variable 'stack11_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 72, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_47), but are not present in its tracked objects:   <tf.Variable 'stack12_short_1_dw_conv/kernel:0' shape=(5, 5, 144, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_47), but are not present in its tracked objects:   <tf.Variable 'stack12_short_1_dw_conv/kernel:0' shape=(5, 5, 144, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_44), but are not present in its tracked objects:   <tf.Variable 'stack12_short_2_conv/kernel:0' shape=(1, 1, 144, 208) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_44), but are not present in its tracked objects:   <tf.Variable 'stack12_short_2_conv/kernel:0' shape=(1, 1, 144, 208) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_45), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_1_prim_conv/kernel:0' shape=(1, 1, 144, 436) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_45), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_1_prim_conv/kernel:0' shape=(1, 1, 144, 436) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_48), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 436, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_48), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 436, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_46), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 144, 872) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_46), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 144, 872) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_49), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 872, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_49), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 872, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_50), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 872, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_50), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 872, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_51), but are not present in its tracked objects:   <tf.Variable 'stack12_down_dw_conv/kernel:0' shape=(5, 5, 872, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_51), but are not present in its tracked objects:   <tf.Variable 'stack12_down_dw_conv/kernel:0' shape=(5, 5, 872, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_47), but are not present in its tracked objects:   <tf.Variable 'stack12_se_1_conv/kernel:0' shape=(1, 1, 872, 220) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_47), but are not present in its tracked objects:   <tf.Variable 'stack12_se_1_conv/kernel:0' shape=(1, 1, 872, 220) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_48), but are not present in its tracked objects:   <tf.Variable 'stack12_se_2_conv/kernel:0' shape=(1, 1, 220, 872) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_48), but are not present in its tracked objects:   <tf.Variable 'stack12_se_2_conv/kernel:0' shape=(1, 1, 220, 872) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_49), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_2_prim_conv/kernel:0' shape=(1, 1, 872, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_49), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_2_prim_conv/kernel:0' shape=(1, 1, 872, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_52), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_52), but are not present in its tracked objects:   <tf.Variable 'stack12_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_50), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_1_prim_conv/kernel:0' shape=(1, 1, 208, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_50), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_1_prim_conv/kernel:0' shape=(1, 1, 208, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_53), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_53), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_51), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 208, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_51), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 208, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_54), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_54), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_55), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_55), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_52), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_2_prim_conv/kernel:0' shape=(1, 1, 1248, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_52), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_2_prim_conv/kernel:0' shape=(1, 1, 1248, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_56), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_56), but are not present in its tracked objects:   <tf.Variable 'stack13_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_53), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_1_prim_conv/kernel:0' shape=(1, 1, 208, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_53), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_1_prim_conv/kernel:0' shape=(1, 1, 208, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_57), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_57), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_54), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 208, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_54), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 208, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_58), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_58), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_59), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_59), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_55), but are not present in its tracked objects:   <tf.Variable 'stack14_se_1_conv/kernel:0' shape=(1, 1, 1248, 312) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_55), but are not present in its tracked objects:   <tf.Variable 'stack14_se_1_conv/kernel:0' shape=(1, 1, 1248, 312) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_56), but are not present in its tracked objects:   <tf.Variable 'stack14_se_2_conv/kernel:0' shape=(1, 1, 312, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_56), but are not present in its tracked objects:   <tf.Variable 'stack14_se_2_conv/kernel:0' shape=(1, 1, 312, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_57), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_2_prim_conv/kernel:0' shape=(1, 1, 1248, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_57), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_2_prim_conv/kernel:0' shape=(1, 1, 1248, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_60), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_60), but are not present in its tracked objects:   <tf.Variable 'stack14_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_58), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_1_prim_conv/kernel:0' shape=(1, 1, 208, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_58), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_1_prim_conv/kernel:0' shape=(1, 1, 208, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_61), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_61), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_59), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 208, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_59), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 208, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_62), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_62), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_63), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_63), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_60), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_2_prim_conv/kernel:0' shape=(1, 1, 1248, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_60), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_2_prim_conv/kernel:0' shape=(1, 1, 1248, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_64), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_64), but are not present in its tracked objects:   <tf.Variable 'stack15_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_61), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_1_prim_conv/kernel:0' shape=(1, 1, 208, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_61), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_1_prim_conv/kernel:0' shape=(1, 1, 208, 624) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_65), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_65), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_1_cheap_dw_conv/kernel:0' shape=(3, 3, 624, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_62), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 208, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_62), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_1_short_1_conv/kernel:0' shape=(1, 1, 208, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_66), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_66), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_1_short_2_dw_conv/kernel:0' shape=(1, 5, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_67), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_67), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_1_short_3_dw_conv/kernel:0' shape=(5, 1, 1248, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_63), but are not present in its tracked objects:   <tf.Variable 'stack16_se_1_conv/kernel:0' shape=(1, 1, 1248, 312) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_63), but are not present in its tracked objects:   <tf.Variable 'stack16_se_1_conv/kernel:0' shape=(1, 1, 1248, 312) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_64), but are not present in its tracked objects:   <tf.Variable 'stack16_se_2_conv/kernel:0' shape=(1, 1, 312, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_64), but are not present in its tracked objects:   <tf.Variable 'stack16_se_2_conv/kernel:0' shape=(1, 1, 312, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_65), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_2_prim_conv/kernel:0' shape=(1, 1, 1248, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_65), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_2_prim_conv/kernel:0' shape=(1, 1, 1248, 104) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_68), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_68), but are not present in its tracked objects:   <tf.Variable 'stack16_ghost_2_cheap_dw_conv/kernel:0' shape=(3, 3, 104, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_66), but are not present in its tracked objects:   <tf.Variable 'pre_conv/kernel:0' shape=(1, 1, 208, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.convolution_66), but are not present in its tracked objects:   <tf.Variable 'pre_conv/kernel:0' shape=(1, 1, 208, 1248) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Change BatchNormalization momentum and epsilon default value.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Layer tf.nn.convolution was passed non-JSON-serializable arguments. Arguments had types: {'filters': <class 'keras.src.backend.tensorflow.core.Variable'>, 'strides': [<class 'int'>, <class 'int'>], 'padding': <class 'str'>, 'data_format': <class 'str'>, 'dilations': (<class 'int'>, <class 'int'>)}. They cannot be serialized out when saving the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tf_keras/src/engine/node.py:221\u001b[0m, in \u001b[0;36mNode.serialize\u001b[0;34m(self, make_node_key, node_conversion_map)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_json_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/json/__init__.py:234\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tf_keras/src/saving/legacy/saved_model/json_utils.py:237\u001b[0m, in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bytes__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: obj\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to serialize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to JSON. Unrecognized type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to serialize <KerasVariable shape=(3, 3, 3, 20), dtype=float32, path=stem_conv/kernel> to JSON. Unrecognized type <class 'keras.src.backend.tensorflow.core.Variable'>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#GhostFaceNetV2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Strides of 2\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m \u001b[43mGhostFaceNets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuildin_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mghostnetv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGDC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbn_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbn_epsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets\u001b[38;5;241m.\u001b[39madd_l2_regularizer_2_model(basic_model, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, apply_to_batch_normal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets\u001b[38;5;241m.\u001b[39mreplace_ReLU_with_PReLU(basic_model)\n",
      "File \u001b[0;32m~/Documents/BTP/Buffalo re-identification/Buffalo-re-identification/GhostFaceNets.py:63\u001b[0m, in \u001b[0;36mbuildin_models\u001b[0;34m(stem_model, dropout, emb_shape, input_shape, output_layer, bn_momentum, bn_epsilon, add_pointwise_conv, pointwise_conv_act, use_bias, scale, weights, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ii, keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mBatchNormalization):\n\u001b[1;32m     62\u001b[0m             ii\u001b[38;5;241m.\u001b[39mmomentum, ii\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m=\u001b[39m bn_momentum, bn_epsilon\n\u001b[0;32m---> 63\u001b[0m     xx \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m inputs \u001b[38;5;241m=\u001b[39m xx\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     66\u001b[0m nn \u001b[38;5;241m=\u001b[39m xx\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/keras/src/models/cloning.py:206\u001b[0m, in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function, call_function, recursive, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m call_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `call_function` is only supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor Functional models. Received model of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_function=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclone_function\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m     )\n\u001b[0;32m--> 206\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serialization_lib\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    208\u001b[0m     config, custom_objects\u001b[38;5;241m=\u001b[39m{model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m}\n\u001b[1;32m    209\u001b[0m )\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/keras/src/saving/serialization_lib.py:244\u001b[0m, in \u001b[0;36mserialize_keras_object\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    226\u001b[0m     ts_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m x: (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m         )\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__typespec__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistered_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    242\u001b[0m     }\n\u001b[0;32m--> 244\u001b[0m inner_config \u001b[38;5;241m=\u001b[39m \u001b[43m_get_class_or_fn_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m config_with_public_class \u001b[38;5;241m=\u001b[39m serialize_with_public_class(\n\u001b[1;32m    246\u001b[0m     obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, inner_config\n\u001b[1;32m    247\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_with_public_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/keras/src/saving/serialization_lib.py:372\u001b[0m, in \u001b[0;36m_get_class_or_fn_config\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# All classes:\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_config\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 372\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    375\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `get_config()` method of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should return \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma dict. It returned: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m         )\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tf_keras/src/engine/functional.py:786\u001b[0m, in \u001b[0;36mFunctional.get_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;66;03m# Check whether the class has a constructor compatible with a Functional\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;66;03m# model or if it has a custom constructor.\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_functional_like_constructor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# Only return a Functional config if the constructor is the same\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;66;03m# as that of a Functional model. This excludes subclassed Functional\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# models with a custom __init__.\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m     config \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[43mget_network_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;66;03m# Try to autogenerate config\u001b[39;00m\n\u001b[1;32m    789\u001b[0m     xtra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(config\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tf_keras/src/engine/functional.py:1585\u001b[0m, in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn, config)\u001b[0m\n\u001b[1;32m   1581\u001b[0m     node_key \u001b[38;5;241m=\u001b[39m _make_node_key(layer\u001b[38;5;241m.\u001b[39mname, original_node_index)\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node_key \u001b[38;5;129;01min\u001b[39;00m network\u001b[38;5;241m.\u001b[39m_network_nodes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node\u001b[38;5;241m.\u001b[39mis_input:\n\u001b[1;32m   1583\u001b[0m         \u001b[38;5;66;03m# The node is relevant to the model:\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m         \u001b[38;5;66;03m# add to filtered_inbound_nodes.\u001b[39;00m\n\u001b[0;32m-> 1585\u001b[0m         node_data \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_make_node_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_conversion_map\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1588\u001b[0m         filtered_inbound_nodes\u001b[38;5;241m.\u001b[39mappend(node_data)\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Functional) \u001b[38;5;129;01mand\u001b[39;00m set_layers_legacy:\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/tf_keras/src/engine/node.py:224\u001b[0m, in \u001b[0;36mNode.serialize\u001b[0;34m(self, make_node_key, node_conversion_map)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     kwarg_types \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28mtype\u001b[39m, kwargs)\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m was passed non-JSON-serializable arguments. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments had types: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(kwarg_types)\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. They cannot be serialized out when saving the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m     )\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# `kwargs` is added to each Tensor in the first arg. This should be\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# changed in a future version of the serialization format.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserialize_first_arg_tensor\u001b[39m(t):\n",
      "\u001b[0;31mTypeError\u001b[0m: Layer tf.nn.convolution was passed non-JSON-serializable arguments. Arguments had types: {'filters': <class 'keras.src.backend.tensorflow.core.Variable'>, 'strides': [<class 'int'>, <class 'int'>], 'padding': <class 'str'>, 'data_format': <class 'str'>, 'dilations': (<class 'int'>, <class 'int'>)}. They cannot be serialized out when saving the model."
     ]
    }
   ],
   "source": [
    "#GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> L2 regularizer value from basic_model: 0.00025\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n",
      ">>>> L2 regularizer value from basic_model: 0.00025\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n"
     ]
    }
   ],
   "source": [
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CosFaceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.CosFaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.CosFaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subcenter ArcFace Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "data_path = data_basic_path + '_112x112_folders'\n",
    "eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/faces_emore_112x112_folders'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Change BatchNormalization momentum and epsilon default value.\n",
      ">>>> Convert ReLU: activation_96 --> activation_96\n",
      ">>>> Convert ReLU: activation_97 --> activation_97\n",
      ">>>> Convert ReLU: activation_98 --> activation_98\n",
      ">>>> Convert ReLU: activation_99 --> activation_99\n",
      ">>>> Convert ReLU: activation_100 --> activation_100\n",
      ">>>> Convert ReLU: activation_101 --> activation_101\n",
      ">>>> Convert ReLU: activation_102 --> activation_102\n",
      ">>>> Convert ReLU: activation_103 --> activation_103\n",
      ">>>> Convert ReLU: activation_104 --> activation_104\n",
      ">>>> Convert ReLU: activation_105 --> activation_105\n",
      ">>>> Convert ReLU: activation_107 --> activation_107\n",
      ">>>> Convert ReLU: activation_108 --> activation_108\n",
      ">>>> Convert ReLU: activation_109 --> activation_109\n",
      ">>>> Convert ReLU: activation_111 --> activation_111\n",
      ">>>> Convert ReLU: activation_112 --> activation_112\n",
      ">>>> Convert ReLU: activation_113 --> activation_113\n",
      ">>>> Convert ReLU: activation_114 --> activation_114\n",
      ">>>> Convert ReLU: activation_115 --> activation_115\n",
      ">>>> Convert ReLU: activation_116 --> activation_116\n",
      ">>>> Convert ReLU: activation_117 --> activation_117\n",
      ">>>> Convert ReLU: activation_118 --> activation_118\n",
      ">>>> Convert ReLU: activation_119 --> activation_119\n",
      ">>>> Convert ReLU: activation_120 --> activation_120\n",
      ">>>> Convert ReLU: activation_121 --> activation_121\n",
      ">>>> Convert ReLU: activation_123 --> activation_123\n",
      ">>>> Convert ReLU: activation_124 --> activation_124\n",
      ">>>> Convert ReLU: activation_125 --> activation_125\n",
      ">>>> Convert ReLU: activation_127 --> activation_127\n",
      ">>>> Convert ReLU: activation_128 --> activation_128\n",
      ">>>> Convert ReLU: activation_129 --> activation_129\n",
      ">>>> Convert ReLU: activation_131 --> activation_131\n",
      ">>>> Convert ReLU: activation_132 --> activation_132\n",
      ">>>> Convert ReLU: activation_133 --> activation_133\n",
      ">>>> Convert ReLU: activation_134 --> activation_134\n",
      ">>>> Convert ReLU: activation_135 --> activation_135\n",
      ">>>> Convert ReLU: activation_137 --> activation_137\n",
      ">>>> Convert ReLU: activation_138 --> activation_138\n",
      ">>>> Convert ReLU: activation_139 --> activation_139\n",
      ">>>> Convert ReLU: activation_140 --> activation_140\n",
      ">>>> Convert ReLU: activation_141 --> activation_141\n",
      ">>>> Convert ReLU: activation_143 --> activation_143\n",
      ">>>> Change BatchNormalization momentum and epsilon default value.\n",
      ">>>> Convert ReLU: activation_144 --> activation_144\n",
      ">>>> Convert ReLU: activation_145 --> activation_145\n",
      ">>>> Convert ReLU: activation_146 --> activation_146\n",
      ">>>> Convert ReLU: activation_147 --> activation_147\n",
      ">>>> Convert ReLU: activation_148 --> activation_148\n",
      ">>>> Convert ReLU: activation_149 --> activation_149\n",
      ">>>> Convert ReLU: activation_150 --> activation_150\n",
      ">>>> Convert ReLU: activation_151 --> activation_151\n",
      ">>>> Convert ReLU: activation_152 --> activation_152\n",
      ">>>> Convert ReLU: activation_153 --> activation_153\n",
      ">>>> Convert ReLU: activation_155 --> activation_155\n",
      ">>>> Convert ReLU: activation_156 --> activation_156\n",
      ">>>> Convert ReLU: activation_157 --> activation_157\n",
      ">>>> Convert ReLU: activation_159 --> activation_159\n",
      ">>>> Convert ReLU: activation_160 --> activation_160\n",
      ">>>> Convert ReLU: activation_161 --> activation_161\n",
      ">>>> Convert ReLU: activation_162 --> activation_162\n",
      ">>>> Convert ReLU: activation_163 --> activation_163\n",
      ">>>> Convert ReLU: activation_164 --> activation_164\n",
      ">>>> Convert ReLU: activation_165 --> activation_165\n",
      ">>>> Convert ReLU: activation_166 --> activation_166\n",
      ">>>> Convert ReLU: activation_167 --> activation_167\n",
      ">>>> Convert ReLU: activation_168 --> activation_168\n",
      ">>>> Convert ReLU: activation_169 --> activation_169\n",
      ">>>> Convert ReLU: activation_171 --> activation_171\n",
      ">>>> Convert ReLU: activation_172 --> activation_172\n",
      ">>>> Convert ReLU: activation_173 --> activation_173\n",
      ">>>> Convert ReLU: activation_175 --> activation_175\n",
      ">>>> Convert ReLU: activation_176 --> activation_176\n",
      ">>>> Convert ReLU: activation_177 --> activation_177\n",
      ">>>> Convert ReLU: activation_179 --> activation_179\n",
      ">>>> Convert ReLU: activation_180 --> activation_180\n",
      ">>>> Convert ReLU: activation_181 --> activation_181\n",
      ">>>> Convert ReLU: activation_182 --> activation_182\n",
      ">>>> Convert ReLU: activation_183 --> activation_183\n",
      ">>>> Convert ReLU: activation_185 --> activation_185\n",
      ">>>> Convert ReLU: activation_186 --> activation_186\n",
      ">>>> Convert ReLU: activation_187 --> activation_187\n",
      ">>>> Convert ReLU: activation_188 --> activation_188\n",
      ">>>> Convert ReLU: activation_189 --> activation_189\n",
      ">>>> Convert ReLU: activation_191 --> activation_191\n"
     ]
    }
   ],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> L2 regularizer value from basic_model: 0.00025\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n",
      ">>>> L2 regularizer value from basic_model: 0.00025\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n",
      "Shape of bins: (3,)\n",
      "First few elements in bins: ('datasets/faces_emore_112x112_folders/00007/7_6.jpg', 'datasets/faces_emore_112x112_folders/00004/4_5.jpg', False)\n"
     ]
    }
   ],
   "source": [
    "#GhostFaceNetV1\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GhostFaceNetV2\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Init type by loss function name...\n",
      ">>>> Train arcface...\n",
      ">>>> Init softmax dataset...\n",
      ">>>> reloaded from dataset backup: faces_emore_112x112_folders_shuffle.npz\n",
      ">>>> Image length: 100, Image class length: 100, classes: 10\n",
      ">>>> Add L2 regularizer to model output layer, output_weight_decay = 0.000500\n",
      ">>>> Add arcface layer, arc_kwargs={'loss_top_k': 3, 'append_norm': False, 'partial_fc_split': 0, 'name': 'arcface'}, vpl_kwargs={'vpl_lambda': 0.15, 'start_iters': 0, 'allowed_delta': 200}...\n",
      ">>>> loss_weights: {'arcface': 1}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <tf_keras.src.optimizers.sgd.SGD object at 0x157c43e50>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m      3\u001b[0m sch \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: losses\u001b[38;5;241m.\u001b[39mArcfaceLoss(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlossTopK\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m},\n\u001b[1;32m      5\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: losses\u001b[38;5;241m.\u001b[39mArcfaceLoss(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlossTopK\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m},\n\u001b[1;32m      6\u001b[0m ]\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BTP/GhostFaceNets/train.py:571\u001b[0m, in \u001b[0;36mTrain.train\u001b[0;34m(self, train_schedule, initial_epoch)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_single_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m initial_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbottleneckOnly\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m sch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstop_training \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/BTP/GhostFaceNets/train.py:544\u001b[0m, in \u001b[0;36mTrain.train_single_scheduler\u001b[0;34m(self, epoch, loss, initial_epoch, lossWeight, optimizer, bottleneckOnly, lossTopK, type, embLossTypes, embLossWeights, tripletAlpha)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 544\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__basic_train__\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>>> Train \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m DONE!!! epochs = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, model.stop_training = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mepoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstop_training))\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>>> My history:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/BTP/GhostFaceNets/train.py:420\u001b[0m, in \u001b[0;36mTrain.__basic_train__\u001b[0;34m(self, epochs, initial_epoch)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__basic_train__\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs, initial_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcur_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m      \u001b[38;5;66;03m# Update callback if needed\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# Update the callbacks with the new model checkpoint and learning rate scheduler\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    424\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_checkpoint_weights,\n\u001b[1;32m    425\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_checkpoint_full,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;66;03m# Add any other callbacks you need here\u001b[39;00m\n\u001b[1;32m    429\u001b[0m ]\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/conda/envs/tf_env/lib/python3.9/site-packages/keras/src/optimizers/__init__.py:97\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Optimizer):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret optimizer identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <tf_keras.src.optimizers.sgd.SGD object at 0x157c43e50>"
     ]
    }
   ],
   "source": [
    "\"\"\" First, Train with `lossTopK = 3` \"\"\"\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer, \"lossTopK\": 3},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50, \"lossTopK\": 3},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Then drop non-dominant subcenters and high-confident noisy data, which is `>75 degrees` \"\"\"\n",
    "import data_drop_top_k\n",
    "# data_drop_top_k.data_drop_top_k('./checkpoints/TT_mobilenet_topk_bs256.h5', '/datasets/faces_casia_112x112_folders/', limit=20)\n",
    "new_data_path = data_drop_top_k.data_drop_top_k(tt.model, tt.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train with the new dataset again, this time `lossTopK = 1` \"\"\"\n",
    "tt.reset_dataset(new_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you can continue training the model or start training again and considering the generated dataset as a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models from scatch using the new generated dataset\n",
    "\n",
    "# New Cleaned Dataset\n",
    "data_path = 'Path_To_New_Generated_Dataset'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
