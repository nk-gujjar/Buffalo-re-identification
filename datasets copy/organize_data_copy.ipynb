{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to original dataset and the target directories\n",
    "original_dataset_path = \"dataset\"\n",
    "arcface_dataset_path = \"MS1MV2/images\"\n",
    "retinaface_dataset_path = \"MS1MV3/aligned_images\"\n",
    "\n",
    "# Ensure target directories exist\n",
    "os.makedirs(arcface_dataset_path, exist_ok=True)\n",
    "os.makedirs(retinaface_dataset_path, exist_ok=True)\n",
    "\n",
    "# CSV and bin file paths\n",
    "arcface_csv = \"MS1MV2/arcface_labels.csv\"\n",
    "retinaface_csv = \"MS1MV3/retinaface_labels.csv\"\n",
    "arcface_bin = \"MS1MV2/arcface_pairs.bin\"\n",
    "retinaface_bin = \"MS1MV3/retinaface_pairs.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to copy images and structure to target folder\n",
    "def convert_to_target_format(src_path, dest_path, csv_file, bin_file):\n",
    "    label_map = []\n",
    "    image_paths = []\n",
    "\n",
    "    for identity in os.listdir(src_path):\n",
    "        identity_path = os.path.join(src_path, identity)\n",
    "        if os.path.isdir(identity_path):\n",
    "            # Create identity folder in target path with zero-padded identity name\n",
    "            target_identity_folder = os.path.join(dest_path, identity.zfill(5))\n",
    "            os.makedirs(target_identity_folder, exist_ok=True)\n",
    "\n",
    "            # Copy each image and record its label\n",
    "            for image_name in os.listdir(identity_path):\n",
    "                src_image_path = os.path.join(identity_path, image_name)\n",
    "                dest_image_path = os.path.join(target_identity_folder, image_name)\n",
    "                shutil.copy2(src_image_path, dest_image_path)\n",
    "\n",
    "                # Record image path and label for CSV\n",
    "                image_paths.append(f\"{target_identity_folder}/{image_name}\")\n",
    "                label_map.append(int(identity))\n",
    "\n",
    "    # Write CSV file with image paths and labels\n",
    "    with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"image_path\", \"label\"])\n",
    "        for img_path, label in zip(image_paths, label_map):\n",
    "            writer.writerow([img_path, label])\n",
    "\n",
    "    # Generate image pairs for binary file\n",
    "    pairs = []\n",
    "    for i in range(len(image_paths)):\n",
    "        for j in range(i + 1, len(image_paths)):\n",
    "            same_label = label_map[i] == label_map[j]\n",
    "            pairs.append((image_paths[i], image_paths[j], same_label))\n",
    "\n",
    "    # Randomly shuffle pairs to mix positive and negative samples\n",
    "    random.shuffle(pairs)\n",
    "\n",
    "    # Save pairs to a binary file\n",
    "    with open(bin_file, \"wb\") as f:\n",
    "        pickle.dump(pairs, f)\n",
    "\n",
    "    print(f\"Dataset conversion complete for {dest_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conversion complete for MS1MV2/images.\n",
      "Dataset conversion complete for MS1MV3/aligned_images.\n"
     ]
    }
   ],
   "source": [
    "# Convert to MS1MV2 (MS1M-ArcFace) format and generate CSV and bin files\n",
    "convert_to_target_format(original_dataset_path, arcface_dataset_path, arcface_csv, arcface_bin)\n",
    "\n",
    "# Convert to MS1MV3 (MS1M-RetinaFace) format and generate CSV and bin files\n",
    "convert_to_target_format(original_dataset_path, retinaface_dataset_path, retinaface_csv, retinaface_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conversion complete for datasets/ms1m-retinaface-t1_112x112_folders with CSV and bin files.\n",
      "Dataset conversion complete for datasets/faces_emore_112x112_folders with CSV and bin files.\n",
      "RetinaFace eval paths: ['datasets/ms1m-retinaface-t1/lfw.bin', 'datasets/ms1m-retinaface-t1/cfp_fp.bin', 'datasets/ms1m-retinaface-t1/agedb_30.bin']\n",
      "ArcFace eval paths: ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Paths for original dataset and new datasets (MS1MV2 and MS1MV3)\n",
    "original_dataset_path = \"dataset\"\n",
    "arcface_dataset_path = \"datasets/faces_emore_112x112_folders\"\n",
    "retinaface_dataset_path = \"datasets/ms1m-retinaface-t1_112x112_folders\"\n",
    "\n",
    "# Ensure target directories exist\n",
    "os.makedirs(arcface_dataset_path, exist_ok=True)\n",
    "os.makedirs(retinaface_dataset_path, exist_ok=True)\n",
    "\n",
    "# CSV and bin file paths\n",
    "arcface_csv = \"datasets/faces_emore/arcface_labels.csv\"\n",
    "retinaface_csv = \"datasets/ms1m-retinaface-t1/retinaface_labels.csv\"\n",
    "arcface_bin_files = [\n",
    "    \"datasets/faces_emore/lfw.bin\",\n",
    "    \"datasets/faces_emore/cfp_fp.bin\",\n",
    "    \"datasets/faces_emore/agedb_30.bin\"\n",
    "]\n",
    "retinaface_bin_files = [\n",
    "    \"datasets/ms1m-retinaface-t1/lfw.bin\",\n",
    "    \"datasets/ms1m-retinaface-t1/cfp_fp.bin\",\n",
    "    \"datasets/ms1m-retinaface-t1/agedb_30.bin\"\n",
    "]\n",
    "\n",
    "# Function to process the dataset, create CSV and bin files\n",
    "def convert_to_target_format(src_path, dest_path, csv_file, bin_files):\n",
    "    label_map = []\n",
    "    image_paths = []\n",
    "\n",
    "    # Process each identity in the source dataset\n",
    "    for identity in os.listdir(src_path):\n",
    "        identity_path = os.path.join(src_path, identity)\n",
    "        if os.path.isdir(identity_path):\n",
    "            # Create identity folder in target path with zero-padded identity name\n",
    "            target_identity_folder = os.path.join(dest_path, identity.zfill(5))\n",
    "            os.makedirs(target_identity_folder, exist_ok=True)\n",
    "\n",
    "            # Copy images and record path and label\n",
    "            for image_name in os.listdir(identity_path):\n",
    "                src_image_path = os.path.join(identity_path, image_name)\n",
    "                dest_image_path = os.path.join(target_identity_folder, image_name)\n",
    "                shutil.copy2(src_image_path, dest_image_path)\n",
    "\n",
    "                # Record image path and label\n",
    "                image_paths.append(f\"{target_identity_folder}/{image_name}\")\n",
    "                label_map.append(int(identity))\n",
    "\n",
    "    # Ensure the directory for CSV file exists\n",
    "    csv_directory = os.path.dirname(csv_file)\n",
    "    os.makedirs(csv_directory, exist_ok=True)\n",
    "\n",
    "    # Write CSV with image paths and labels\n",
    "    with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"image_path\", \"label\"])\n",
    "        for img_path, label in zip(image_paths, label_map):\n",
    "            writer.writerow([img_path, label])\n",
    "\n",
    "    # Generate and save image pairs to binary files\n",
    "    pairs = []\n",
    "    for i in range(len(image_paths)):\n",
    "        for j in range(i + 1, len(image_paths)):\n",
    "            same_label = label_map[i] == label_map[j]\n",
    "            pairs.append((image_paths[i], image_paths[j], same_label))\n",
    "\n",
    "    # Randomly shuffle pairs for variety\n",
    "    random.shuffle(pairs)\n",
    "\n",
    "    # Save pairs to each binary file specified\n",
    "    for bin_file in bin_files:\n",
    "        # Ensure the directory for the binary file exists\n",
    "        bin_directory = os.path.dirname(bin_file)\n",
    "        os.makedirs(bin_directory, exist_ok=True)\n",
    "\n",
    "        with open(bin_file, \"wb\") as f:\n",
    "            pickle.dump(pairs, f)\n",
    "\n",
    "    print(f\"Dataset conversion complete for {dest_path} with CSV and bin files.\")\n",
    "\n",
    "# Convert to MS1MV3 (RetinaFace) format and generate CSV and bin files\n",
    "convert_to_target_format(original_dataset_path, retinaface_dataset_path, retinaface_csv, retinaface_bin_files)\n",
    "\n",
    "# Convert to MS1MV2 (ArcFace) format and generate CSV and bin files\n",
    "convert_to_target_format(original_dataset_path, arcface_dataset_path, arcface_csv, arcface_bin_files)\n",
    "\n",
    "# Evaluation paths to use in models\n",
    "retinaface_eval_paths = [os.path.join(\"datasets/ms1m-retinaface-t1\", os.path.basename(path)) for path in retinaface_bin_files]\n",
    "arcface_eval_paths = [os.path.join(\"datasets/faces_emore\", os.path.basename(path)) for path in arcface_bin_files]\n",
    "\n",
    "print(\"RetinaFace eval paths:\", retinaface_eval_paths)\n",
    "print(\"ArcFace eval paths:\", arcface_eval_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
