{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define your model class (same as training)\n",
    "class EfficientNetForAnimalRecognition(nn.Module):\n",
    "    def __init__(self, num_classes=1072):\n",
    "        super().__init__()\n",
    "        self.efficientnet = timm.create_model('efficientnet_b3', pretrained=False, num_classes=0)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(1536, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.efficientnet.forward_features(x)\n",
    "        features = self.global_pool(features)\n",
    "        features = torch.flatten(features, 1)\n",
    "        return self.classifier(features)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        features = self.efficientnet.forward_features(x)\n",
    "        features = self.global_pool(features)\n",
    "        return torch.flatten(features, 1)\n",
    "\n",
    "# Image preprocessing (must match training)\n",
    "def preprocess_image(img_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((300, 300)),  # EfficientNet-B3 prefers 300x300\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet normalization\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    return transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Load model and weights\n",
    "def load_model(path, device):\n",
    "    model = EfficientNetForAnimalRecognition()\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Extract normalized feature vector\n",
    "def get_normalized_features(model, image_tensor, device):\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model.extract_features(image_tensor)\n",
    "        features = features / features.norm(dim=1, keepdim=True)  # Normalize to unit vector\n",
    "    return features.cpu().numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9254955\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = load_model(\"best_model.pth\", device)\n",
    "    \n",
    "    image1 = preprocess_image(\"sample_img/2_a.jpg\")\n",
    "    image2 = preprocess_image(\"sample_img/2_b.jpg\")\n",
    "\n",
    "    feat1 = get_normalized_features(model, image1, device)\n",
    "    feat2 = get_normalized_features(model, image2, device)\n",
    "\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarity = cosine_similarity(feat1, feat2)\n",
    "\n",
    "    print(\"Cosine Similarity:\", similarity[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
